# Kubeflow å®‰è£…å’Œé…ç½®

## ğŸ“‘ ç›®å½•

- [Kubeflow å®‰è£…å’Œé…ç½®](#kubeflow-å®‰è£…å’Œé…ç½®)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [1 æ¦‚è¿°](#1-æ¦‚è¿°)
    - [1.1 æ ¸å¿ƒç»„ä»¶](#11-æ ¸å¿ƒç»„ä»¶)
  - [2 å‰ç½®è¦æ±‚](#2-å‰ç½®è¦æ±‚)
    - [2.1 Kubernetes ç‰ˆæœ¬](#21-kubernetes-ç‰ˆæœ¬)
    - [2.2 èµ„æºè¦æ±‚](#22-èµ„æºè¦æ±‚)
    - [2.3 GPU æ”¯æŒï¼ˆå¯é€‰ï¼‰](#23-gpu-æ”¯æŒå¯é€‰)
  - [3 å®‰è£…æ­¥éª¤](#3-å®‰è£…æ­¥éª¤)
    - [3.1 ä½¿ç”¨ kfctl å®‰è£…ï¼ˆæ¨èï¼‰](#31-ä½¿ç”¨-kfctl-å®‰è£…æ¨è)
    - [3.2 ä½¿ç”¨ Kubeflow Manifests å®‰è£…](#32-ä½¿ç”¨-kubeflow-manifests-å®‰è£…)
    - [3.3 ä½¿ç”¨ Helm å®‰è£…ï¼ˆç®€åŒ–ç‰ˆï¼‰](#33-ä½¿ç”¨-helm-å®‰è£…ç®€åŒ–ç‰ˆ)
  - [4 éªŒè¯å®‰è£…](#4-éªŒè¯å®‰è£…)
    - [4.1 æ£€æŸ¥ Pod çŠ¶æ€](#41-æ£€æŸ¥-pod-çŠ¶æ€)
    - [4.2 è®¿é—® Dashboard](#42-è®¿é—®-dashboard)
  - [5 é…ç½®ç¤ºä¾‹](#5-é…ç½®ç¤ºä¾‹)
    - [5.1 Pipeline ç¤ºä¾‹](#51-pipeline-ç¤ºä¾‹)
    - [5.2 Katib è¶…å‚æ•°è°ƒä¼˜ç¤ºä¾‹](#52-katib-è¶…å‚æ•°è°ƒä¼˜ç¤ºä¾‹)
  - [6 ç›¸å…³æ–‡æ¡£](#6-ç›¸å…³æ–‡æ¡£)

---

## 1 æ¦‚è¿°

**Kubeflow** æ˜¯ Kubernetes åŸç”Ÿæœºå™¨å­¦ä¹ å¹³å°ï¼Œæä¾›æ¨¡å‹è®­ç»ƒã€æ¨¡å‹éƒ¨ç½²ã€å·¥ä½œæµç¼–æ’
ç­‰åŠŸèƒ½ã€‚

### 1.1 æ ¸å¿ƒç»„ä»¶

- **Kubeflow Pipelines**ï¼šæœºå™¨å­¦ä¹ å·¥ä½œæµç¼–æ’
- **Katib**ï¼šè‡ªåŠ¨è¶…å‚æ•°è°ƒä¼˜
- **KServe**ï¼šæ¨¡å‹æœåŠ¡æ¡†æ¶
- **Training Operator**ï¼šåˆ†å¸ƒå¼è®­ç»ƒæ”¯æŒ
- **Central Dashboard**ï¼šç»Ÿä¸€ç®¡ç†ç•Œé¢

---

## 2 å‰ç½®è¦æ±‚

### 2.1 Kubernetes ç‰ˆæœ¬

- **Kubernetes**ï¼šâ‰¥ 1.28
- **K3s**ï¼šâ‰¥ 1.30ï¼ˆè¾¹ç¼˜åœºæ™¯ï¼‰

### 2.2 èµ„æºè¦æ±‚

- **Master èŠ‚ç‚¹**ï¼šâ‰¥ 4 CPUï¼Œâ‰¥ 8 GB RAM
- **Worker èŠ‚ç‚¹**ï¼šâ‰¥ 8 CPUï¼Œâ‰¥ 16 GB RAMï¼ˆGPU èŠ‚ç‚¹éœ€è¦ GPUï¼‰

### 2.3 GPU æ”¯æŒï¼ˆå¯é€‰ï¼‰

- **NVIDIA GPU**ï¼šâ‰¥ NVIDIA T4ï¼ˆæ¨ç†ï¼‰æˆ– A100ï¼ˆè®­ç»ƒï¼‰
- **NVIDIA GPU Operator**ï¼šéœ€è¦å®‰è£… GPU Operator

---

## 3 å®‰è£…æ­¥éª¤

### 3.1 ä½¿ç”¨ kfctl å®‰è£…ï¼ˆæ¨èï¼‰

```bash
# ä¸‹è½½ kfctl
export KFCTL_VERSION=1.7.0
wget https://github.com/kubeflow/kfctl/releases/download/v${KFCTL_VERSION}/kfctl_v${KFCTL_VERSION}-linux-amd64.tar.gz
tar -xzf kfctl_v${KFCTL_VERSION}-linux-amd64.tar.gz
sudo mv kfctl /usr/local/bin/

# è®¾ç½®ç¯å¢ƒå˜é‡
export KF_NAME=kubeflow
export BASE_DIR=/opt/kubeflow
export KF_DIR=${BASE_DIR}/${KF_NAME}
export CONFIG_URI="https://raw.githubusercontent.com/kubeflow/manifests/v1.7-branch/kfdef/kfdef_k8s_istio.v1.7.0.yaml"

# åˆ›å»ºç›®å½•
mkdir -p ${KF_DIR}
cd ${KF_DIR}

# ä¸‹è½½é…ç½®æ–‡ä»¶
kfctl build -V -f ${CONFIG_URI}
kfctl apply -V -f ${CONFIG_URI}
```

### 3.2 ä½¿ç”¨ Kubeflow Manifests å®‰è£…

```bash
# å…‹éš† manifests ä»“åº“
git clone https://github.com/kubeflow/manifests.git
cd manifests

# å®‰è£… Kubeflow
while ! kustomize build example | kubectl apply -f -; do echo "Retrying to apply resources"; sleep 10; done
```

### 3.3 ä½¿ç”¨ Helm å®‰è£…ï¼ˆç®€åŒ–ç‰ˆï¼‰

```bash
# æ·»åŠ  Kubeflow Helm ä»“åº“
helm repo add kubeflow https://charts.kubeflow.org
helm repo update

# å®‰è£… Kubeflow
helm install kubeflow kubeflow/kubeflow -n kubeflow --create-namespace
```

---

## 4 éªŒè¯å®‰è£…

### 4.1 æ£€æŸ¥ Pod çŠ¶æ€

```bash
# æ£€æŸ¥æ‰€æœ‰ Pod æ˜¯å¦è¿è¡Œ
kubectl get pods -n kubeflow

# é¢„æœŸè¾“å‡ºï¼ˆéƒ¨åˆ†ï¼‰
NAME                                     READY   STATUS    RESTARTS   AGE
kubeflow-pipelines-profile-controller    1/1     Running   0          5m
katib-controller                         1/1     Running   0          5m
kserve-controller                        1/1     Running   0          5m
```

### 4.2 è®¿é—® Dashboard

```bash
# ç«¯å£è½¬å‘
kubectl port-forward -n istio-system svc/istio-ingressgateway 8080:80

# è®¿é—® Dashboard
open http://localhost:8080
```

---

## 5 é…ç½®ç¤ºä¾‹

### 5.1 Pipeline ç¤ºä¾‹

```python
from kfp import dsl

@dsl.pipeline(
    name='llm-training-pipeline',
    description='LLM training pipeline'
)
def llm_training_pipeline():
    # æ•°æ®é¢„å¤„ç†
    preprocess = dsl.ContainerOp(
        name='preprocess',
        image='preprocess:latest',
        command=['python', 'preprocess.py'],
        arguments=['--input', '/data/raw', '--output', '/data/processed']
    )

    # æ¨¡å‹è®­ç»ƒ
    train = dsl.ContainerOp(
        name='train',
        image='train:latest',
        command=['python', 'train.py'],
        arguments=['--data', '/data/processed', '--output', '/models/llm'],
        resources={
            'gpu': 1,
            'memory': '32Gi'
        }
    )
    train.after(preprocess)

    # æ¨¡å‹éªŒè¯
    validate = dsl.ContainerOp(
        name='validate',
        image='validate:latest',
        command=['python', 'validate.py'],
        arguments=['--model', '/models/llm', '--data', '/data/test']
    )
    validate.after(train)
```

### 5.2 Katib è¶…å‚æ•°è°ƒä¼˜ç¤ºä¾‹

```yaml
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  name: llm-hyperparameter-tuning
spec:
  algorithm:
    algorithmName: bayesian-optimization
  parameters:
    - name: learning-rate
      parameterType: double
      feasibleSpace:
        min: "0.001"
        max: "0.1"
    - name: batch-size
      parameterType: int
      feasibleSpace:
        min: "16"
        max: "128"
  objective:
    type: maximize
    objectiveMetricName: accuracy
  parallelTrialCount: 3
  maxTrialCount: 20
  trialTemplate:
    trialSpec:
      apiVersion: batch/v1
      kind: Job
      spec:
        template:
          spec:
            containers:
              - name: training-container
                image: train:latest
                command:
                  - python
                  - train.py
                  - --lr=${trialParameters.learning-rate}
                  - --batch-size=${trialParameters.batch-size}
```

---

## 6 ç›¸å…³æ–‡æ¡£

- [`README.md`](README.md) - AI/ML å®ç°ç»†èŠ‚æ€»è§ˆ
- [`../../02-views/10-quick-views/ai-ml-architecture-view.md`](../../02-views/10-quick-views/ai-ml-architecture-view.md) -
  AI/ML æ¶æ„è§†è§’
- [`gpu-scheduling.md`](gpu-scheduling.md) - GPU èµ„æºè°ƒåº¦é…ç½®

---

**æ›´æ–°æ—¶é—´**ï¼š2025-11-05 **ç‰ˆæœ¬**ï¼šv1.0
