# GPU èµ„æºè°ƒåº¦é…ç½®

## ğŸ“‘ ç›®å½•

- [GPU èµ„æºè°ƒåº¦é…ç½®](#gpu-èµ„æºè°ƒåº¦é…ç½®)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [1 æ¦‚è¿°](#1-æ¦‚è¿°)
    - [1.1 æ ¸å¿ƒæ¦‚å¿µ](#11-æ ¸å¿ƒæ¦‚å¿µ)
  - [2 NVIDIA GPU Operator å®‰è£…](#2-nvidia-gpu-operator-å®‰è£…)
    - [2.1 å‰ç½®è¦æ±‚](#21-å‰ç½®è¦æ±‚)
    - [2.2 å®‰è£…æ­¥éª¤](#22-å®‰è£…æ­¥éª¤)
    - [2.3 éªŒè¯å®‰è£…](#23-éªŒè¯å®‰è£…)
  - [3 GPU èµ„æºåˆ†é…](#3-gpu-èµ„æºåˆ†é…)
    - [3.1 Pod çº§åˆ«çš„ GPU è¯·æ±‚](#31-pod-çº§åˆ«çš„-gpu-è¯·æ±‚)
    - [3.2 GPU å…±äº«é…ç½®](#32-gpu-å…±äº«é…ç½®)
    - [3.3 Deployment çº§åˆ«çš„ GPU é…ç½®](#33-deployment-çº§åˆ«çš„-gpu-é…ç½®)
  - [4 MIG é…ç½®](#4-mig-é…ç½®)
    - [4.1 MIG æ¦‚è¿°](#41-mig-æ¦‚è¿°)
    - [4.2 MIG é…ç½®æ­¥éª¤](#42-mig-é…ç½®æ­¥éª¤)
    - [4.3 MIG Pod é…ç½®](#43-mig-pod-é…ç½®)
  - [5 GPU ç›‘æ§](#5-gpu-ç›‘æ§)
    - [5.1 DCGMï¼ˆNVIDIA Data Center GPU Managerï¼‰](#51-dcgmnvidia-data-center-gpu-manager)
    - [5.2 Prometheus é›†æˆ](#52-prometheus-é›†æˆ)
  - [6 ç›¸å…³æ–‡æ¡£](#6-ç›¸å…³æ–‡æ¡£)
  - [7 2025 å¹´æœ€æ–°å®è·µ](#7-2025-å¹´æœ€æ–°å®è·µ)
    - [7.1 GPU Operator 2.0+ æ–°ç‰¹æ€§ï¼ˆ2025ï¼‰](#71-gpu-operator-20-æ–°ç‰¹æ€§2025)
    - [7.2 MIGï¼ˆMulti-Instance GPUï¼‰æ”¯æŒï¼ˆ2025ï¼‰](#72-migmulti-instance-gpuæ”¯æŒ2025)
    - [7.3 è¾¹ç¼˜ GPU è°ƒåº¦ï¼ˆ2025ï¼‰](#73-è¾¹ç¼˜-gpu-è°ƒåº¦2025)
  - [8 å®é™…åº”ç”¨æ¡ˆä¾‹](#8-å®é™…åº”ç”¨æ¡ˆä¾‹)
    - [æ¡ˆä¾‹ 1ï¼šå¤šç§Ÿæˆ· GPU å…±äº«](#æ¡ˆä¾‹-1å¤šç§Ÿæˆ·-gpu-å…±äº«)
    - [æ¡ˆä¾‹ 2ï¼šGPU è‡ªåŠ¨æ‰©ç¼©å®¹](#æ¡ˆä¾‹-2gpu-è‡ªåŠ¨æ‰©ç¼©å®¹)
    - [æ¡ˆä¾‹ 3ï¼šGPU æ—¶é—´åˆ‡ç‰‡](#æ¡ˆä¾‹-3gpu-æ—¶é—´åˆ‡ç‰‡)

---

## 1 æ¦‚è¿°

**GPU èµ„æºè°ƒåº¦**æ˜¯ AI/ML å·¥ä½œè´Ÿè½½çš„å…³é”®ç»„ä»¶ï¼Œé€šè¿‡ Kubernetes GPU æ’ä»¶å®ç° GPU èµ„
æºçš„åŠ¨æ€è°ƒåº¦å’Œç®¡ç†ã€‚

### 1.1 æ ¸å¿ƒæ¦‚å¿µ

- **GPU èµ„æºåˆ†é…**ï¼šPod çº§åˆ«çš„ GPU èµ„æºè¯·æ±‚å’Œé™åˆ¶
- **GPU å…±äº«**ï¼šå¤šä¸ª Pod å…±äº« GPU èµ„æº
- **MIGï¼ˆMulti-Instance GPUï¼‰**ï¼šGPU èµ„æºåˆ†å‰²
- **GPU ç›‘æ§**ï¼šGPU ä½¿ç”¨æƒ…å†µç›‘æ§

---

## 2 NVIDIA GPU Operator å®‰è£…

### 2.1 å‰ç½®è¦æ±‚

- **Kubernetes**ï¼šâ‰¥ 1.28
- **NVIDIA GPU**ï¼šâ‰¥ NVIDIA T4
- **NVIDIA é©±åŠ¨**ï¼šâ‰¥ 535.54

### 2.2 å®‰è£…æ­¥éª¤

```bash
# æ·»åŠ  NVIDIA Helm ä»“åº“
helm repo add nvidia https://helm.ngc.nvidia.com/nvidia
helm repo update

# å®‰è£… NVIDIA GPU Operator
helm install --wait gpu-operator nvidia/gpu-operator \
  -n gpu-operator --create-namespace \
  --set driver.enabled=true \
  --set toolkit.enabled=true \
  --set devicePlugin.enabled=true \
  --set operator.defaultRuntime=containerd
```

### 2.3 éªŒè¯å®‰è£…

```bash
# æ£€æŸ¥ GPU Operator Pod
kubectl get pods -n gpu-operator

# æ£€æŸ¥ GPU èŠ‚ç‚¹
kubectl get nodes -l nvidia.com/gpu.present=true

# æ£€æŸ¥ GPU èµ„æº
kubectl describe node <gpu-node-name> | grep nvidia.com/gpu
```

---

## 3 GPU èµ„æºåˆ†é…

### 3.1 Pod çº§åˆ«çš„ GPU è¯·æ±‚

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: gpu-training-pod
spec:
  containers:
    - name: training-container
      image: pytorch/pytorch:2.1.0-cuda11.8-cudnn8-runtime
      resources:
        limits:
          nvidia.com/gpu: 1 # è¯·æ±‚ 1 ä¸ª GPU
          memory: "32Gi"
          cpu: "8"
        requests:
          nvidia.com/gpu: 1
          memory: "32Gi"
          cpu: "8"
```

### 3.2 GPU å…±äº«é…ç½®

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: device-plugin-config
  namespace: gpu-operator
data:
  config.yaml: |
    version: v1
    sharing:
      timeSlicing:
        resources:
          - name: nvidia.com/gpu
            replicas: 4  # æ¯ä¸ª GPU æ”¯æŒ 4 ä¸ª Pod å…±äº«
```

### 3.3 Deployment çº§åˆ«çš„ GPU é…ç½®

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: llm-inference
spec:
  replicas: 3
  template:
    spec:
      containers:
        - name: llm-service
          image: my-registry/llm-service:v1.0.0
          resources:
            limits:
              nvidia.com/gpu: 1
            requests:
              nvidia.com/gpu: 1
```

---

## 4 MIG é…ç½®

### 4.1 MIG æ¦‚è¿°

**MIGï¼ˆMulti-Instance GPUï¼‰**æ˜¯ NVIDIA A100/H100 GPU çš„ç‰¹æ€§ï¼Œå¯ä»¥å°†ä¸€ä¸ª GPU åˆ†å‰²
æˆå¤šä¸ªç‹¬ç«‹çš„ GPU å®ä¾‹ã€‚

### 4.2 MIG é…ç½®æ­¥éª¤

```bash
# å¯ç”¨ MIG
nvidia-smi -mig 1

# åˆ›å»º MIG å®ä¾‹ï¼ˆç¤ºä¾‹ï¼šA100 åˆ†å‰²ä¸º 7 ä¸ªå®ä¾‹ï¼‰
nvidia-smi mig -cgi 19,19,19,19,19,19,19 -C

# é…ç½® GPU Operator ä½¿ç”¨ MIG
kubectl patch node <gpu-node-name> \
  -p '{"spec":{"gpu":{"migStrategy":"mixed"}}}'
```

### 4.3 MIG Pod é…ç½®

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: mig-pod
spec:
  containers:
    - name: mig-container
      image: pytorch/pytorch:2.1.0-cuda11.8-cudnn8-runtime
      resources:
        limits:
          nvidia.com/mig-1g.10gb: 1 # ä½¿ç”¨ MIG å®ä¾‹
```

---

## 5 GPU ç›‘æ§

### 5.1 DCGMï¼ˆNVIDIA Data Center GPU Managerï¼‰

```bash
# å®‰è£… DCGM Exporter
helm install dcgm-exporter nvidia/dcgm-exporter \
  -n gpu-operator

# æŸ¥çœ‹ GPU æŒ‡æ ‡
kubectl port-forward -n gpu-operator svc/dcgm-exporter 9400:9400
curl http://localhost:9400/metrics
```

### 5.2 Prometheus é›†æˆ

```yaml
apiVersion: v1
kind: ServiceMonitor
metadata:
  name: dcgm-exporter
  namespace: gpu-operator
spec:
  selector:
    matchLabels:
      app: dcgm-exporter
  endpoints:
    - port: metrics
      interval: 30s
```

---

## 6 ç›¸å…³æ–‡æ¡£

- [`README.md`](README.md) - AI/ML å®ç°ç»†èŠ‚æ€»è§ˆ
- [`kubeflow-setup.md`](kubeflow-setup.md) - Kubeflow å®‰è£…å’Œé…ç½®
- [`kserve-deployment.md`](kserve-deployment.md) - KServe æ¨¡å‹éƒ¨ç½²

## 7 2025 å¹´æœ€æ–°å®è·µ

### 7.1 GPU Operator 2.0+ æ–°ç‰¹æ€§ï¼ˆ2025ï¼‰

**æœ€æ–°ç‰ˆæœ¬**ï¼šGPU Operator 2.0+ï¼ˆ2025 å¹´ï¼‰

**æ–°ç‰¹æ€§**ï¼š

- **å¤š GPU å‚å•†æ”¯æŒ**ï¼šæ”¯æŒ NVIDIAã€AMDã€Intel GPU
- **åŠ¨æ€ GPU åˆ†é…**ï¼šæ”¯æŒåŠ¨æ€ GPU åˆ†é…
- **æ€§èƒ½ä¼˜åŒ–**ï¼šGPU åˆ©ç”¨ç‡æå‡ 30%

**å®‰è£…æœ€æ–°ç‰ˆæœ¬**ï¼š

```bash
# å®‰è£… GPU Operator 2.0
helm install gpu-operator nvidia/gpu-operator \
  --version 2.0.0 \
  --namespace gpu-operator-system \
  --create-namespace
```

### 7.2 MIGï¼ˆMulti-Instance GPUï¼‰æ”¯æŒï¼ˆ2025ï¼‰

**2025 å¹´è¶‹åŠ¿**ï¼šä½¿ç”¨ MIG å®ç° GPU ç»†ç²’åº¦å…±äº«

**é…ç½®ç¤ºä¾‹**ï¼š

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: device-plugin-config
  namespace: gpu-operator-system
data:
  config.yaml: |
    version: v1
    sharing:
      timeSlicing:
        resources:
        - name: nvidia.com/gpu
          replicas: 4
```

### 7.3 è¾¹ç¼˜ GPU è°ƒåº¦ï¼ˆ2025ï¼‰

**2025 å¹´è¶‹åŠ¿**ï¼šåœ¨è¾¹ç¼˜èŠ‚ç‚¹è°ƒåº¦ GPU å·¥ä½œè´Ÿè½½

**é…ç½®ç¤ºä¾‹**ï¼š

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: edge-gpu-app
spec:
  nodeSelector:
    node-type: edge
    accelerator: nvidia-tesla-t4
  containers:
  - name: app
    image: gpu-app:latest
    resources:
      limits:
        nvidia.com/gpu: 1
```

## 8 å®é™…åº”ç”¨æ¡ˆä¾‹

### æ¡ˆä¾‹ 1ï¼šå¤šç§Ÿæˆ· GPU å…±äº«

**åœºæ™¯**ï¼šåœ¨å¤šç§Ÿæˆ·ç¯å¢ƒä¸­å…±äº« GPU èµ„æº

**å®ç°æ–¹æ¡ˆ**ï¼š

```yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: gpu-quota
  namespace: tenant-a
spec:
  hard:
    requests.nvidia.com/gpu: "2"
    limits.nvidia.com/gpu: "4"
---
apiVersion: v1
kind: Pod
metadata:
  name: gpu-pod
  namespace: tenant-a
spec:
  containers:
  - name: app
    image: gpu-app:latest
    resources:
      requests:
        nvidia.com/gpu: 1
      limits:
        nvidia.com/gpu: 1
```

**æ•ˆæœ**ï¼š

- èµ„æºéš”ç¦»ï¼šæ¯ä¸ªç§Ÿæˆ·æœ‰ç‹¬ç«‹çš„ GPU é…é¢
- å…¬å¹³è°ƒåº¦ï¼šé€šè¿‡ ResourceQuota å…¬å¹³è°ƒåº¦
- èµ„æºåˆ©ç”¨ï¼šæé«˜ GPU åˆ©ç”¨ç‡

### æ¡ˆä¾‹ 2ï¼šGPU è‡ªåŠ¨æ‰©ç¼©å®¹

**åœºæ™¯**ï¼šæ ¹æ®è´Ÿè½½è‡ªåŠ¨æ‰©ç¼©å®¹ GPU å·¥ä½œè´Ÿè½½

**å®ç°æ–¹æ¡ˆ**ï¼š

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: gpu-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: gpu-app
  minReplicas: 1
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: nvidia.com/gpu
      target:
        type: Utilization
        averageUtilization: 80
```

**æ•ˆæœ**ï¼š

- è‡ªåŠ¨æ‰©ç¼©å®¹ï¼šæ ¹æ® GPU åˆ©ç”¨ç‡è‡ªåŠ¨æ‰©ç¼©å®¹
- èµ„æºä¼˜åŒ–ï¼šä¼˜åŒ– GPU èµ„æºä½¿ç”¨
- æˆæœ¬æ§åˆ¶ï¼šé™ä½ GPU è¿è¡Œæˆæœ¬

### æ¡ˆä¾‹ 3ï¼šGPU æ—¶é—´åˆ‡ç‰‡

**åœºæ™¯**ï¼šä½¿ç”¨ GPU æ—¶é—´åˆ‡ç‰‡å®ç° GPU å…±äº«

**å®ç°æ–¹æ¡ˆ**ï¼š

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: device-plugin-config
  namespace: gpu-operator-system
data:
  config.yaml: |
    version: v1
    sharing:
      timeSlicing:
        resources:
        - name: nvidia.com/gpu
          replicas: 4
---
apiVersion: v1
kind: Pod
metadata:
  name: gpu-shared-pod
spec:
  containers:
  - name: app
    image: gpu-app:latest
    resources:
      limits:
        nvidia.com/gpu: 1  # å…±äº« GPU çš„ 1/4
```

**æ•ˆæœ**ï¼š

- GPU å…±äº«ï¼šå¤šä¸ª Pod å…±äº«åŒä¸€ä¸ª GPU
- èµ„æºæ•ˆç‡ï¼šæé«˜ GPU åˆ©ç”¨ç‡
- æˆæœ¬ä¼˜åŒ–ï¼šé™ä½ GPU ä½¿ç”¨æˆæœ¬

---

**æ›´æ–°æ—¶é—´**ï¼š2025-11-15 **ç‰ˆæœ¬**ï¼šv1.1 **çŠ¶æ€**ï¼šâœ… åŒ…å« 2025 å¹´æœ€æ–°å®è·µ
