# 7 å±‚ 4 åŸŸæ¨¡å‹å®ç°ç»†èŠ‚

## ğŸ“‘ ç›®å½•

- [ğŸ“‘ ç›®å½•](#-ç›®å½•)
- [1 æ¦‚è¿°](#1-æ¦‚è¿°)
- [2 L1 ç¡¬ä»¶èµ„æºå±‚å®ç°](#2-l1-ç¡¬ä»¶èµ„æºå±‚å®ç°)
- [3 L2 è®¡ç®—è™šæ‹Ÿå±‚å®ç°](#3-l2-è®¡ç®—è™šæ‹Ÿå±‚å®ç°)
- [4 L3 åˆ†å¸ƒå¼è°ƒåº¦å±‚å®ç°](#4-l3-åˆ†å¸ƒå¼è°ƒåº¦å±‚å®ç°)
- [5 L4 åˆ†å¸ƒå¼æ•°æ®é¢å®ç°](#5-l4-åˆ†å¸ƒå¼æ•°æ®é¢å®ç°)
- [6 L5 æ§åˆ¶é¢ & æ²»ç†å®ç°](#6-l5-æ§åˆ¶é¢--æ²»ç†å®ç°)
- [7 L6 å¯è§‚æµ‹æ€§ & æ•…éšœæ²»ç†å®ç°](#7-l6-å¯è§‚æµ‹æ€§--æ•…éšœæ²»ç†å®ç°)
- [8 L7 åº”ç”¨äº¤ä»˜å±‚å®ç°](#8-l7-åº”ç”¨äº¤ä»˜å±‚å®ç°)

---

## 1 æ¦‚è¿°

æœ¬æ–‡æ¡£æä¾› `system_view.md` æå‡ºçš„"7 å±‚ 4 åŸŸ"æ¨¡å‹çš„å®é™…éƒ¨ç½²é…ç½®å’Œå®ç°ç»†èŠ‚ã€‚

### 1.1 æ¨¡å‹å›é¡¾

**7 å±‚æ¨¡å‹**ï¼š

- L1ï¼šç¡¬ä»¶èµ„æºå±‚
- L2ï¼šè®¡ç®—è™šæ‹Ÿå±‚
- L3ï¼šåˆ†å¸ƒå¼è°ƒåº¦å±‚
- L4ï¼šåˆ†å¸ƒå¼æ•°æ®é¢
- L5ï¼šæ§åˆ¶é¢ & æ²»ç†
- L6ï¼šå¯è§‚æµ‹æ€§ & æ•…éšœæ²»ç†
- L7ï¼šåº”ç”¨äº¤ä»˜å±‚

**4 åŸŸæ¨¡å‹**ï¼š

- CPï¼šæ§åˆ¶é¢ï¼ˆæœ€ç»ˆä¸€è‡´æ€§ï¼‰
- DPï¼šæ•°æ®é¢ï¼ˆæ¯«ç§’çº§ç¡®å®šæ€§ï¼‰
- MDï¼šå…ƒæ•°æ®é¢ï¼ˆå¼ºä¸€è‡´æˆ–åˆ†å¸ƒå¼å…±è¯†ï¼‰
- SECï¼šå®‰å…¨é¢ï¼ˆé›¶ä¿¡ä»» + æœ€å°æƒé™ï¼‰

### 1.2 å‚è€ƒæ–‡æ¡£

- **ç†è®ºè®º
  è¯**ï¼š[`../00-theory/07-system-model/7-layer-4-domain-formalization.md`](../00-theory/07-system-model/7-layer-4-domain-formalization.md)
- **ç³»ç»Ÿè§†è§’**ï¼š[`../../system_view.md`](../../system_view.md)
- **æ•´åˆæŒ‡å—**ï¼š[`../SYSTEM-VIEW-INTEGRATION.md`](../SYSTEM-VIEW-INTEGRATION.md)

---

## 2 L1 ç¡¬ä»¶èµ„æºå±‚å®ç°

### 2.1 CPU åˆ†åŒºé…ç½®

#### 2.1.1 è™šæ‹ŸåŒ–ï¼švCPU Pinning

**KVM é…ç½®**ï¼š

```xml
<!-- libvirt XML -->
<domain type='kvm'>
  <cputune>
    <vcpupin vcpu='0' cpuset='0'/>
    <vcpupin vcpu='1' cpuset='1'/>
    <vcpupin vcpu='2' cpuset='2'/>
    <vcpupin vcpu='3' cpuset='3'/>
  </cputune>
  <numatune>
    <memory mode='strict' nodeset='0'/>
    <memnode cellid='0' mode='strict' nodeset='0'/>
  </numatune>
</domain>
```

**Nova é…ç½®**ï¼š

```yaml
# nova.conf
[compute]
cpu_dedicated_set = 0-7
cpu_shared_set = 8-15
vcpu_pin_set = 0-7
```

#### 2.1.2 å®¹å™¨åŒ–ï¼šcgroup v2

**cgroup v2 é…ç½®**ï¼š

```bash
# åˆ›å»º cgroup
mkdir -p /sys/fs/cgroup/kubepods.slice/pod-xxx
echo "+cpu +memory +io" > /sys/fs/cgroup/kubepods.slice/cgroup.subtree_control

# CPU é…é¢
echo "50000" > /sys/fs/cgroup/kubepods.slice/pod-xxx/cpu.max
echo "100000" > /sys/fs/cgroup/kubepods.slice/pod-xxx/cpu.weight

# å†…å­˜é™åˆ¶
echo "1G" > /sys/fs/cgroup/kubepods.slice/pod-xxx/memory.max
```

**Kubernetes é…ç½®**ï¼š

```yaml
apiVersion: v1
kind: Pod
spec:
  containers:
    - name: app
      resources:
        requests:
          cpu: "500m"
          memory: "1Gi"
        limits:
          cpu: "1"
          memory: "2Gi"
```

#### 2.1.3 æ²™ç›’åŒ–ï¼šFirecracker CPU é…ç½®

**Firecracker é…ç½®**ï¼š

```json
{
  "boot-source": {
    "kernel_image_path": "/vmlinux",
    "boot_args": "console=ttyS0 reboot=k panic=1 pci=off"
  },
  "machine-config": {
    "vcpu_count": 2,
    "mem_size_mib": 128,
    "smt": false
  },
  "cpu-template": "T2"
}
```

### 2.2 å†…å­˜åˆ†åŒºé…ç½®

#### 2.2.1 è™šæ‹ŸåŒ–ï¼šEPT/NPT + IOMMU

**IOMMU é…ç½®**ï¼š

```bash
# å¯ç”¨ IOMMU
GRUB_CMDLINE_LINUX="intel_iommu=on iommu=pt"

# éªŒè¯ IOMMU
dmesg | grep -i iommu
```

**libvirt é…ç½®**ï¼š

```xml
<domain type='kvm'>
  <memory unit='KiB'>2097152</memory>
  <memoryBacking>
    <hugepages>
      <page size='1' unit='GiB'/>
    </hugepages>
  </memoryBacking>
  <iommu model='intel'>
    <driver intremap='on'/>
  </iommu>
</domain>
```

#### 2.2.2 å®¹å™¨åŒ–ï¼šcgroup memory

**cgroup memory é…ç½®**ï¼š

```bash
# å†…å­˜é™åˆ¶
echo "1G" > /sys/fs/cgroup/kubepods.slice/pod-xxx/memory.max
echo "100M" > /sys/fs/cgroup/kubepods.slice/pod-xxx/memory.high

# OOM killer é…ç½®
echo "100" > /sys/fs/cgroup/kubepods.slice/pod-xxx/memory.oom.group
```

#### 2.2.3 æ²™ç›’åŒ–ï¼šFirecracker Balloon

**Balloon é…ç½®**ï¼š

```json
{
  "balloon": {
    "size_mib": 128,
    "deflate_on_oom": true,
    "stats_polling_interval_s": 10
  }
}
```

### 2.3 I/O è™šæ‹ŸåŒ–é…ç½®

#### 2.3.1 è™šæ‹ŸåŒ–ï¼šSR-IOV

**SR-IOV é…ç½®**ï¼š

```bash
# å¯ç”¨ SR-IOV
echo 4 > /sys/class/net/eth0/device/sriov_numvfs

# ç»‘å®š VF åˆ°é©±åŠ¨
echo 0000:01:10.0 > /sys/bus/pci/drivers/igbvf/bind
```

**libvirt é…ç½®**ï¼š

```xml
<interface type='hostdev' managed='yes'>
  <source>
    <address type='pci' domain='0x0000' bus='0x01' slot='0x10' function='0x0'/>
  </source>
  <mac address='52:54:00:6f:aa:01'/>
</interface>
```

#### 2.3.2 å®¹å™¨åŒ–ï¼šcgroup blkio

**blkio é…ç½®**ï¼š

```bash
# IO é™åˆ¶
echo "8:0 1048576" > /sys/fs/cgroup/kubepods.slice/pod-xxx/io.max
echo "100" > /sys/fs/cgroup/kubepods.slice/pod-xxx/io.weight
```

---

## 3 L2 è®¡ç®—è™šæ‹Ÿå±‚å®ç°

### 3.1 è™šæ‹ŸåŒ–ï¼šQEMU/KVM

**QEMU å‘½ä»¤è¡Œ**ï¼š

```bash
qemu-system-x86_64 \
  -enable-kvm \
  -cpu host \
  -m 2G \
  -smp 2 \
  -drive file=disk.qcow2,format=qcow2 \
  -netdev user,id=net0 \
  -device virtio-net-pci,netdev=net0 \
  -device virtio-balloon-pci \
  -monitor qmp \
  -qmp unix:/tmp/qmp.sock,server,nowait
```

**libvirt é…ç½®**ï¼šå‚è§
[`../01-virtualization/qemu-config.md`](../01-virtualization/qemu-config.md)

### 3.2 å®¹å™¨åŒ–ï¼šcontainerd

**containerd é…ç½®**ï¼š

```toml
version = 2
[plugins."io.containerd.grpc.v1.cri".containerd]
  snapshotter = "overlayfs"
  default_runtime_name = "runc"

[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc]
  runtime_type = "io.containerd.runc.v2"
  [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
    SystemdCgroup = true
```

**Docker é…ç½®**ï¼šå‚è§
[`../02-containerization/docker-examples.md`](../02-containerization/docker-examples.md)

### 3.3 æ²™ç›’åŒ–ï¼šgVisor

**gVisor é…ç½®**ï¼š

```bash
# å®‰è£… runsc
wget https://storage.googleapis.com/gvisor/releases/release/latest/x86_64/runsc
sudo mv runsc /usr/local/bin
sudo chmod +x /usr/local/bin/runsc

# é…ç½® containerd
cat > /etc/containerd/config.toml <<EOF
[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runsc]
  runtime_type = "io.containerd.runsc.v1"
EOF
```

**è¯¦ç»†é…ç½®**ï¼šå‚è§
[`../03-sandboxing/gvisor-setup.md`](../03-sandboxing/gvisor-setup.md)

### 3.4 æ²™ç›’åŒ–ï¼šFirecracker

**Firecracker é…ç½®**ï¼š

```json
{
  "boot-source": {
    "kernel_image_path": "/vmlinux",
    "boot_args": "console=ttyS0 reboot=k panic=1 pci=off"
  },
  "drives": [
    {
      "drive_id": "rootfs",
      "path_on_host": "/rootfs.ext4",
      "is_root_device": true,
      "is_read_only": false
    }
  ],
  "network-interfaces": [
    {
      "iface_id": "net0",
      "guest_mac": "AA:FC:00:00:00:01",
      "host_dev_name": "veth0"
    }
  ],
  "machine-config": {
    "vcpu_count": 2,
    "mem_size_mib": 128,
    "smt": false
  }
}
```

**è¯¦ç»†é…ç½®**ï¼šå‚è§
[`../03-sandboxing/firecracker-config.md`](../03-sandboxing/firecracker-config.md)

---

## 4 L3 åˆ†å¸ƒå¼è°ƒåº¦å±‚å®ç°

### 4.1 Kubernetes Scheduler

**è°ƒåº¦å™¨é…ç½®**ï¼š

```yaml
apiVersion: kubescheduler.config.k8s.io/v1
kind: KubeSchedulerConfiguration
profiles:
  - schedulerName: default-scheduler
    plugins:
      preFilter:
        enabled:
          - name: NodeResourcesFit
          - name: NodePorts
      filter:
        enabled:
          - name: NodeResourcesFit
          - name: NodeAffinity
      score:
        enabled:
          - name: NodeResourcesFit
            weight: 1
          - name: NodeAffinity
            weight: 10
```

### 4.2 OpenStack Nova Scheduler

**Nova Filter Scheduler**ï¼š

```yaml
# nova.conf
[scheduler]
driver = filter_scheduler
scheduler_host_subset_size = 1

[scheduler]
available_filters = nova.scheduler.filters.all_filters
enabled_filters = RetryFilter, AvailabilityZoneFilter, ComputeFilter, RamFilter, DiskFilter, ComputeCapabilitiesFilter, ImagePropertiesFilter, ServerGroupAntiAffinityFilter, ServerGroupAffinityFilter

[scheduler]
weight_classes = nova.scheduler.weights.all_weighers
weight_compute = 1.0
weight_ram = 1.0
weight_disk = 1.0
```

### 4.3 çƒ­è¿ç§»å®ç°

**KVM Live Migration**ï¼š

```bash
# çƒ­è¿ç§»
virsh migrate --live \
  --persistent \
  --undefinesource \
  --copy-storage-all \
  vm1 \
  qemu+ssh://dest-host/system
```

**CRIU å®¹å™¨è¿ç§»**ï¼ˆå®éªŒæ€§ï¼‰ï¼š

```bash
# Checkpoint
criu dump \
  -t $(pgrep -f container) \
  --images-dir /checkpoint/container \
  --leave-running

# Restore
criu restore \
  --images-dir /checkpoint/container \
  --restore-detached
```

---

## 5 L4 åˆ†å¸ƒå¼æ•°æ®é¢å®ç°

### 5.1 ç½‘ç»œå­ç³»ç»Ÿ

#### 5.1.1 CNI é…ç½®

**Calico CNI**ï¼š

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: calico-config
  namespace: kube-system
data:
  calico_backend: "bird"
  veth_mtu: "1440"
  ipam_type: "calico-ipam"
```

**Cilium CNI**ï¼š

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: cilium-config
  namespace: kube-system
data:
  enable-ipv4: "true"
  enable-ipv6: "false"
  enable-bpf-masquerade: "true"
  enable-remote-node-identity: "true"
```

#### 5.1.2 Service Meshï¼šIstio

**Istio é…ç½®**ï¼š

```yaml
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: reviews
spec:
  hosts:
    - reviews
  http:
    - route:
        - destination:
            host: reviews
            subset: v1
          weight: 50
        - destination:
            host: reviews
            subset: v3
          weight: 50
```

**è¯¦ç»†é…ç½®**ï¼šå‚è§
[`../04-service-mesh/istio-config.md`](../04-service-mesh/istio-config.md)

### 5.2 å­˜å‚¨å­ç³»ç»Ÿ

#### 5.2.1 CSI é©±åŠ¨é…ç½®

**Ceph RBD CSI**ï¼š

```yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: ceph-rbd
provisioner: rbd.csi.ceph.com
parameters:
  clusterID: ceph-cluster
  pool: k8s-pool
  imageFormat: "2"
  imageFeatures: layering
```

#### 5.2.2 å­˜å‚¨å·é…ç½®

**PVC é…ç½®**ï¼š

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: data-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
  storageClassName: ceph-rbd
```

### 5.3 æ¶ˆæ¯å­ç³»ç»Ÿ

**Kafka é…ç½®**ï¼š

```yaml
apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    replicas: 3
    listeners:
      - name: plain
        port: 9092
        type: internal
        tls: false
      - name: tls
        port: 9093
        type: internal
        tls: true
```

---

## 6 L5 æ§åˆ¶é¢ & æ²»ç†å®ç°

### 6.1 OPA ç­–ç•¥å¼•æ“

**Gatekeeper é…ç½®**ï¼š

```yaml
apiVersion: templates.gatekeeper.sh/v1beta1
kind: ConstraintTemplate
metadata:
  name: k8srequiredlabels
spec:
  crd:
    spec:
      names:
        kind: K8sRequiredLabels
      validation:
        openAPIV3Schema:
          type: object
          properties:
            labels:
              type: array
              items:
                type: string
---
apiVersion: constraints.gatekeeper.sh/v1beta1
kind: K8sRequiredLabels
metadata:
  name: must-have-app-label
spec:
  match:
    kinds:
      - apiGroups: [""]
        kinds: ["Pod"]
  parameters:
    labels: ["app"]
```

**è¯¦ç»†é…ç½®**ï¼šå‚è§
[`../05-opa/gatekeeper-config.md`](../05-opa/gatekeeper-config.md)

### 6.2 Rego ç­–ç•¥ç¤ºä¾‹

**èµ„æºé…é¢ç­–ç•¥**ï¼š

```rego
package kubernetes.admission

deny[msg] {
  input.request.kind.kind == "Pod"
  not input.request.object.metadata.labels.app
  msg := "Pod must have 'app' label"
}

deny[msg] {
  input.request.kind.kind == "Pod"
  cpu := input.request.object.spec.containers[_].resources.requests.cpu
  to_number(cpu) > 2
  msg := "CPU request exceeds limit"
}
```

**è¯¦ç»†ç¤ºä¾‹**ï¼šå‚è§ [`../05-opa/rego-examples.md`](../05-opa/rego-examples.md)

---

## 7 L6 å¯è§‚æµ‹æ€§ & æ•…éšœæ²»ç†å®ç°

### 7.1 Prometheus ç›‘æ§

**Prometheus é…ç½®**ï¼š

```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: "kubernetes-pods"
    kubernetes_sd_configs:
      - role: pod
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
```

### 7.2 Grafana å¯è§†åŒ–

**Grafana Dashboard**ï¼š

```json
{
  "dashboard": {
    "title": "7 Layer 4 Domain Monitoring",
    "panels": [
      {
        "title": "L1 Hardware Resources",
        "targets": [
          {
            "expr": "node_cpu_seconds_total"
          }
        ]
      }
    ]
  }
}
```

### 7.3 Jaeger é“¾è·¯è¿½è¸ª

**Jaeger é…ç½®**ï¼š

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: jaeger-config
data:
  config.yaml: |
    sampling:
      default_strategy:
        type: probabilistic
        param: 0.001
    storage:
      type: elasticsearch
      elasticsearch:
        server_urls: http://elasticsearch:9200
```

### 7.4 ChaosMesh æ··æ²Œå·¥ç¨‹

**Chaos å®éªŒ**ï¼š

```yaml
apiVersion: chaos-mesh.org/v1alpha1
kind: PodChaos
metadata:
  name: pod-kill
spec:
  action: pod-kill
  mode: one
  selector:
    namespaces:
      - default
    labelSelectors:
      app: myapp
  scheduler:
    cron: "@every 5m"
```

---

## 8 L7 åº”ç”¨äº¤ä»˜å±‚å®ç°

### 8.1 CI/CD æµæ°´çº¿

**GitLab CI**ï¼š

```yaml
# .gitlab-ci.yml
stages:
  - build
  - test
  - deploy

build:
  stage: build
  script:
    - docker build -t app:latest .
    - docker push registry.example.com/app:latest

deploy:
  stage: deploy
  script:
    - kubectl apply -f k8s/
```

### 8.2 Argo CD GitOps

**Argo CD Application**ï¼š

```yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: myapp
spec:
  project: default
  source:
    repoURL: https://github.com/example/repo
    targetRevision: main
    path: k8s/
  destination:
    server: https://kubernetes.default.svc
    namespace: default
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
```

### 8.3 Helm Chart

**Chart.yaml**ï¼š

```yaml
apiVersion: v2
name: myapp
description: My Application
type: application
version: 1.0.0
appVersion: "1.0"
```

**values.yaml**ï¼š

```yaml
replicaCount: 3
image:
  repository: registry.example.com/app
  tag: latest
resources:
  requests:
    cpu: 500m
    memory: 512Mi
  limits:
    cpu: 1000m
    memory: 1Gi
```

---

## 9 å±‚é—´äº¤äº’å®ç°

### 9.1 L1 â†’ L2ï¼šèµ„æºæŠ½è±¡

**èµ„æºæä¾›è€…æ¥å£**ï¼š

```python
class ResourceProvider:
    def get_cpu_resources(self):
        """ä» L1 è·å– CPU èµ„æº"""
        pass

    def get_memory_resources(self):
        """ä» L1 è·å–å†…å­˜èµ„æº"""
        pass

    def allocate_resources(self, request):
        """åœ¨ L1 åˆ†é…èµ„æºç»™ L2"""
        pass
```

### 9.2 L2 â†’ L3ï¼šè®¡ç®—å¯¹è±¡æŠ½è±¡

**è®¡ç®—å¯¹è±¡æ¥å£**ï¼š

```python
class ComputeObject:
    def create(self, spec):
        """åˆ›å»ºè®¡ç®—å¯¹è±¡"""
        pass

    def start(self):
        """å¯åŠ¨è®¡ç®—å¯¹è±¡"""
        pass

    def stop(self):
        """åœæ­¢è®¡ç®—å¯¹è±¡"""
        pass

    def snapshot(self):
        """åˆ›å»ºå¿«ç…§"""
        pass
```

### 9.3 L3 â†’ L4ï¼šè°ƒåº¦ç»“æœä¼ é€’

**è°ƒåº¦ç»“æœæ¥å£**ï¼š

```python
class SchedulingResult:
    def get_placement(self):
        """è·å– placement ç»“æœ"""
        pass

    def get_network_config(self):
        """è·å–ç½‘ç»œé…ç½®"""
        pass

    def get_storage_config(self):
        """è·å–å­˜å‚¨é…ç½®"""
        pass
```

---

## 10 æ•…éšœåŸŸéš”ç¦»å®ç°

### 10.1 ç¡¬ä»¶æ•…éšœåŸŸ

**NUMA æ‹“æ‰‘**ï¼š

```bash
# æŸ¥çœ‹ NUMA æ‹“æ‰‘
numactl --hardware

# ç»‘å®šè¿›ç¨‹åˆ° NUMA èŠ‚ç‚¹
numactl --membind=0 --cpunodebind=0 ./app
```

### 10.2 è¿›ç¨‹æ•…éšœåŸŸ

**è¿›ç¨‹éš”ç¦»**ï¼š

```bash
# ä½¿ç”¨ systemd æœåŠ¡éš”ç¦»
[Service]
PrivateTmp=yes
PrivateDevices=yes
ProtectSystem=strict
ProtectHome=yes
```

### 10.3 ç½‘ç»œæ•…éšœåŸŸ

**ç½‘ç»œéš”ç¦»**ï¼š

```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: deny-all
spec:
  podSelector: {}
  policyTypes:
    - Ingress
    - Egress
```

---

## 11 æ€§èƒ½ä¼˜åŒ–

### 11.1 å¯åŠ¨ä¼˜åŒ–

**é¢„åŠ è½½å’Œç¼“å­˜**ï¼š

```bash
# é¢„åŠ è½½é•œåƒ
crictl pull registry.example.com/app:latest

# ä½¿ç”¨å¿«ç…§
firecracker-ctr snapshot create \
  --vm-state-path /snapshots/base-vm-state \
  --mem-file-path /snapshots/base-mem
```

### 11.2 å†…å­˜ä¼˜åŒ–

**å†…å­˜æ± ç®¡ç†**ï¼š

```python
class MemoryPool:
    def __init__(self, size_mb):
        self.pool = []
        self.size_mb = size_mb

    def allocate(self, size):
        """ä»æ± ä¸­åˆ†é…å†…å­˜"""
        pass

    def deallocate(self, ptr):
        """é‡Šæ”¾å†…å­˜å›æ± """
        pass
```

---

## 12 å®‰å…¨å®ç°

### 12.1 é›¶ä¿¡ä»»ç½‘ç»œ

**SPIFFE/SPIRE**ï¼š

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: spire-config
data:
  server.conf: |
    server {
      bind_address = "0.0.0.0"
      bind_port = "8081"
      trust_domain = "example.org"
    }
```

### 12.2 æœ€å°æƒé™åŸåˆ™

**RBAC é…ç½®**ï¼š

```yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: pod-reader
rules:
  - apiGroups: [""]
    resources: ["pods"]
    verbs: ["get", "watch", "list"]
```

---

## 13 ç»“è®º

### 13.1 å®ç°è¦ç‚¹

âœ… **åˆ†å±‚æ¸…æ™°**ï¼šæ¯å±‚éƒ½æœ‰æ˜ç¡®çš„æ¥å£å’Œå®ç° âœ… **æ•…éšœéš”ç¦»**ï¼šæ¯å±‚éƒ½æœ‰ç‹¬ç«‹çš„æ•…éšœåŸŸ
âœ… **æ€§èƒ½ä¼˜åŒ–**ï¼šå¯åŠ¨ã€å†…å­˜ã€ç½‘ç»œå…¨æ–¹ä½ä¼˜åŒ– âœ… **å®‰å…¨åŠ å›º**ï¼šé›¶ä¿¡ä»»ã€æœ€å°æƒé™ã€
å¤šå±‚é˜²æŠ¤

### 13.2 éƒ¨ç½²å»ºè®®

1. **æ¸è¿›éƒ¨ç½²**ï¼šä» L1-L2 å¼€å§‹ï¼Œé€æ­¥æ‰©å±•åˆ° L7
2. **ç›‘æ§å…ˆè¡Œ**ï¼šå…ˆéƒ¨ç½² L6ï¼Œå†éƒ¨ç½²å…¶ä»–å±‚
3. **å®‰å…¨ä¼˜å…ˆ**ï¼šL5 å®‰å…¨ç­–ç•¥å…ˆè¡Œï¼Œå…¶ä»–å±‚ä¾èµ–å®‰å…¨ç­–ç•¥

---

**ç›¸å…³æ–‡æ¡£**ï¼š

- [`../00-theory/07-system-model/7-layer-4-domain-formalization.md`](../00-theory/07-system-model/7-layer-4-domain-formalization.md) -
  ç†è®ºè®ºè¯
- [`../../system_view.md`](../../system_view.md) - ç³»ç»Ÿè§†è§’æ–‡æ¡£
- [`../SYSTEM-VIEW-INTEGRATION.md`](../SYSTEM-VIEW-INTEGRATION.md) - æ•´åˆæŒ‡å—

---

**æ›´æ–°æ—¶é—´**ï¼š2025-11-05 **ç‰ˆæœ¬**ï¼šv1.0 **ç»´æŠ¤è€…**ï¼šåŸºäº system_view.md 7 å±‚ 4
åŸŸæ¨¡å‹å®ç°
