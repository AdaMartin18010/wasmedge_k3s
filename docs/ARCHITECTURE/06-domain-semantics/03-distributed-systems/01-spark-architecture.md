# Spark è½¯ä»¶æ ˆçš„è¯­ä¹‰åˆ†å±‚æ¨¡å‹

## ğŸ“‘ ç›®å½•

- [Spark è½¯ä»¶æ ˆçš„è¯­ä¹‰åˆ†å±‚æ¨¡å‹](#spark-è½¯ä»¶æ ˆçš„è¯­ä¹‰åˆ†å±‚æ¨¡å‹)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [æ¦‚è¿°](#æ¦‚è¿°)
    - [æ ¸å¿ƒæ€æƒ³](#æ ¸å¿ƒæ€æƒ³)
  - [äº”å±‚è¯­ä¹‰æ¶æ„](#äº”å±‚è¯­ä¹‰æ¶æ„)
  - [åˆ†å±‚æ¶ˆè§£çš„æ¼”è¿›è·¯å¾„](#åˆ†å±‚æ¶ˆè§£çš„æ¼”è¿›è·¯å¾„)
  - [æ ¸å¿ƒå¯ç¤º](#æ ¸å¿ƒå¯ç¤º)
  - [æŠ€æœ¯é€‰å‹å»ºè®®](#æŠ€æœ¯é€‰å‹å»ºè®®)
    - [Spark on Kubernetes ä¼˜åŠ¿](#spark-on-kubernetes-ä¼˜åŠ¿)
    - [å®æ–½å»ºè®®](#å®æ–½å»ºè®®)
  - [Spark 3.5/4.0 æœ€æ–°ç‰¹æ€§ï¼ˆ2025ï¼‰](#spark-3540-æœ€æ–°ç‰¹æ€§2025)
    - [Spark 3.5 ä¸»è¦ç‰¹æ€§](#spark-35-ä¸»è¦ç‰¹æ€§)
    - [Spark 4.0 é¢„æœŸç‰¹æ€§ï¼ˆ2025ï¼‰](#spark-40-é¢„æœŸç‰¹æ€§2025)
  - [ä»£ç ç¤ºä¾‹](#ä»£ç ç¤ºä¾‹)
    - [Spark on Kubernetes éƒ¨ç½²ç¤ºä¾‹](#spark-on-kubernetes-éƒ¨ç½²ç¤ºä¾‹)
    - [æ€§èƒ½ä¼˜åŒ–é…ç½®ç¤ºä¾‹](#æ€§èƒ½ä¼˜åŒ–é…ç½®ç¤ºä¾‹)
  - [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)
    - [1. èµ„æºç®¡ç†](#1-èµ„æºç®¡ç†)
    - [2. æ•°æ®å­˜å‚¨](#2-æ•°æ®å­˜å‚¨)
    - [3. ç›‘æ§å’Œè°ƒä¼˜](#3-ç›‘æ§å’Œè°ƒä¼˜)
  - [å®é™…åº”ç”¨æ¡ˆä¾‹](#å®é™…åº”ç”¨æ¡ˆä¾‹)
    - [æ¡ˆä¾‹ 1ï¼šå¤§æ•°æ®æ‰¹å¤„ç†](#æ¡ˆä¾‹-1å¤§æ•°æ®æ‰¹å¤„ç†)
    - [æ¡ˆä¾‹ 2ï¼šå®æ—¶æµå¤„ç†](#æ¡ˆä¾‹-2å®æ—¶æµå¤„ç†)
  - [ç›¸å…³æ–‡æ¡£](#ç›¸å…³æ–‡æ¡£)

---

> **æœ¬æ–‡æ¡£æ˜¯ Spark æ¶æ„åˆ†æçš„ç®€åŒ–ç‰ˆæœ¬ã€‚è¯¦ç»†åˆ†æè¯·å‚è€ƒï¼š**
> [`../04-domain-case-studies/01-spark-semantic-layering.md`](../04-domain-case-studies/01-spark-semantic-layering.md)

## æ¦‚è¿°

æœ¬æ–‡æ¡£ä»**åˆ†å±‚æ¶ˆè§£å¾‹è§†è§’**ç®€è¦åˆ†æ Spark è½¯ä»¶æ ˆçš„è¯­ä¹‰åˆ†å±‚æ¨¡å‹ã€‚

### æ ¸å¿ƒæ€æƒ³

> **Spark ä½œä¸ºåˆ†å¸ƒå¼è®¡ç®—é¢†åŸŸçš„æ ‡æ†ï¼Œå…¶è½¯ä»¶å †æ ˆæœ¬èº«å°±æ˜¯"åˆ†å±‚æ¶ˆè§£å¾‹"çš„æœ€ä½³æ¼”ç»åœºã€‚
> Spark å¦‚ä½•åœ¨è™šæ‹ŸåŒ–/å®¹å™¨åŒ–æµªæ½®ä¸­ï¼Œæ—¢ä¸»åŠ¨æ¶ˆè§£ä¸‹å±‚å¤æ‚æ€§ï¼Œåˆå›ºå®ˆæ ¸å¿ƒè®¡ç®—è¯­ä¹‰ã€‚**

## äº”å±‚è¯­ä¹‰æ¶æ„

1. **å±‚ 1ï¼šç‰©ç†æ‰§è¡Œè¯­ä¹‰å±‚** - JVM/å®¹å™¨/ç½‘ç»œ/ç£ç›˜ï¼ˆæ¶ˆè§£ç‡ï¼š100%ï¼‰
2. **å±‚ 2ï¼šèµ„æºç®¡ç†è¯­ä¹‰å±‚** - Master/Worker æˆ– YARN/K8sï¼ˆæ¶ˆè§£ç‡ï¼š100%ï¼‰
3. **å±‚ 3ï¼šåˆ†å¸ƒå¼è°ƒåº¦è¯­ä¹‰å±‚** - TaskSchedulerï¼ˆæ¶ˆè§£ç‡ï¼š50%ï¼‰
4. **å±‚ 4ï¼šè®¡ç®—å›¾è¯­ä¹‰å±‚** - DAG æ„å»ºï¼ˆæ¶ˆè§£ç‡ï¼š0%ï¼‰
5. **å±‚ 5ï¼šä¸šåŠ¡é¢†åŸŸè¯­ä¹‰å±‚** - ä¸šåŠ¡é€»è¾‘ï¼ˆæ¶ˆè§£ç‡ï¼š0%ï¼‰

## åˆ†å±‚æ¶ˆè§£çš„æ¼”è¿›è·¯å¾„

- **Spark 1.xï¼ˆ2010ï¼‰**ï¼šStandalone æ¨¡å¼ï¼Œæ¶ˆè§£ç‡çº¦ 0%
- **Spark 2.xï¼ˆ2014ï¼‰**ï¼šYARN æ¨¡å¼ï¼Œæ¶ˆè§£ç‡çº¦ 50%
- **Spark 3.xï¼ˆ2020ï¼‰**ï¼šK8s æ¨¡å¼ï¼Œæ¶ˆè§£ç‡çº¦ 80%
- **Spark 4.0ï¼ˆ2024ï¼‰**ï¼šK8s åŸç”Ÿï¼Œæ¶ˆè§£ç‡çº¦ 100%ï¼ˆå±‚ 2ï¼‰

## æ ¸å¿ƒå¯ç¤º

1. **èµ„æºç®¡ç†å±‚å¯ä»¥å®Œå…¨è¢« K8s æ¶ˆè§£**
2. **åˆ†å¸ƒå¼è°ƒåº¦å±‚éƒ¨åˆ†æ¶ˆè§£ï¼Œè®¡ç®—æ„ŸçŸ¥çš„è°ƒåº¦æ— æ³•æ¶ˆè§£**
3. **è®¡ç®—å›¾å’Œä¸šåŠ¡é€»è¾‘æ— æ³•è¢«æ¶ˆè§£**

## æŠ€æœ¯é€‰å‹å»ºè®®

### Spark on Kubernetes ä¼˜åŠ¿

- **ç»Ÿä¸€èµ„æºç®¡ç†**ï¼šä¸ K8s ç”Ÿæ€æ— ç¼é›†æˆ
- **å¼¹æ€§æ‰©ç¼©å®¹**ï¼šåŸºäº K8s HPA è‡ªåŠ¨æ‰©ç¼©å®¹
- **èµ„æºéš”ç¦»**ï¼šåˆ©ç”¨ K8s å‘½åç©ºé—´å’Œèµ„æºé…é¢
- **è¿ç»´ç®€åŒ–**ï¼šç»Ÿä¸€çš„ç›‘æ§å’Œæ—¥å¿—ç®¡ç†
- **æˆæœ¬ä¼˜åŒ–**ï¼šæ›´å¥½çš„èµ„æºåˆ©ç”¨ç‡å’Œæˆæœ¬æ§åˆ¶

### å®æ–½å»ºè®®

**éƒ¨ç½²æ–¹å¼**ï¼š

- **Spark Operator**ï¼šä½¿ç”¨ Spark Operator ç®¡ç† Spark åº”ç”¨
- **åŸç”Ÿ K8s æ¨¡å¼**ï¼šç›´æ¥ä½¿ç”¨ K8s API æäº¤ Spark ä½œä¸š
- **æ··åˆæ¨¡å¼**ï¼šç»“åˆ YARN å’Œ K8s çš„ä¼˜åŠ¿

**æ€§èƒ½ä¼˜åŒ–**ï¼š

- **åŠ¨æ€èµ„æºåˆ†é…**ï¼šå¯ç”¨åŠ¨æ€èµ„æºåˆ†é…
- **æœ¬åœ°å­˜å‚¨**ï¼šä½¿ç”¨æœ¬åœ°å­˜å‚¨æå‡æ€§èƒ½
- **ç½‘ç»œä¼˜åŒ–**ï¼šä¼˜åŒ– Pod é—´ç½‘ç»œé€šä¿¡
- **JVM è°ƒä¼˜**ï¼šé’ˆå¯¹ K8s ç¯å¢ƒè°ƒä¼˜ JVM å‚æ•°

## Spark 3.5/4.0 æœ€æ–°ç‰¹æ€§ï¼ˆ2025ï¼‰

### Spark 3.5 ä¸»è¦ç‰¹æ€§

- **Kubernetes åŸç”Ÿæ¨¡å¼å¢å¼º**ï¼š
  - æ”¯æŒåŠ¨æ€ Executor åˆ†é…
  - æ”¹è¿›çš„ Pod è°ƒåº¦ç­–ç•¥
  - æ›´å¥½çš„èµ„æºåˆ©ç”¨ç‡

- **æ€§èƒ½ä¼˜åŒ–**ï¼š
  - AQEï¼ˆè‡ªé€‚åº”æŸ¥è¯¢æ‰§è¡Œï¼‰å¢å¼º
  - åŠ¨æ€åˆ†åŒºè£å‰ªä¼˜åŒ–
  - å‘é‡åŒ–æ‰§è¡Œå¼•æ“æ”¹è¿›

- **æ•°æ®æºæ”¯æŒ**ï¼š
  - Delta Lake 3.0 é›†æˆ
  - Iceberg è¡¨æ ¼å¼æ”¯æŒ
  - æ”¹è¿›çš„ Parquet è¯»å–æ€§èƒ½

### Spark 4.0 é¢„æœŸç‰¹æ€§ï¼ˆ2025ï¼‰

- **å®Œå…¨ Kubernetes åŸç”Ÿ**ï¼š
  - ç§»é™¤å¯¹ YARN çš„ä¾èµ–
  - åŸç”Ÿ K8s è°ƒåº¦å™¨
  - æ›´å¥½çš„å¤šç§Ÿæˆ·æ”¯æŒ

- **æ€§èƒ½æå‡**ï¼š
  - æŸ¥è¯¢æ€§èƒ½æå‡ 2-3 å€
  - å†…å­˜ä½¿ç”¨ä¼˜åŒ–
  - æ›´å¿«çš„å¯åŠ¨æ—¶é—´

## ä»£ç ç¤ºä¾‹

### Spark on Kubernetes éƒ¨ç½²ç¤ºä¾‹

**ä½¿ç”¨ Spark Operator éƒ¨ç½²**ï¼š

```yaml
apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: spark-pi
  namespace: default
spec:
  type: Scala
  mode: cluster
  image: "gcr.io/spark-operator/spark:v3.5.0"
  imagePullPolicy: Always
  mainClass: org.apache.spark.examples.SparkPi
  mainApplicationFile: "local:///opt/spark/examples/jars/spark-examples_2.12-3.5.0.jar"
  sparkVersion: "3.5.0"
  restartPolicy:
    type: OnFailure
    onFailureRetries: 3
    onFailureRetryInterval: 10
    onSubmissionFailureRetries: 5
    onSubmissionFailureRetryInterval: 20
  driver:
    cores: 1
    coreLimit: "1200m"
    memory: "512m"
    labels:
      version: 3.5.0
    serviceAccount: spark
  executor:
    cores: 1
    instances: 2
    memory: "512m"
    labels:
      version: 3.5.0
```

**ä½¿ç”¨åŸç”Ÿ K8s æ¨¡å¼æäº¤ä½œä¸š**ï¼š

```bash
# æäº¤ Spark ä½œä¸šåˆ° Kubernetes
bin/spark-submit \
  --master k8s://https://kubernetes.default.svc \
  --deploy-mode cluster \
  --name spark-pi \
  --class org.apache.spark.examples.SparkPi \
  --conf spark.executor.instances=5 \
  --conf spark.kubernetes.container.image=apache/spark:3.5.0 \
  --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark \
  local:///opt/spark/examples/jars/spark-examples_2.12-3.5.0.jar
```

### æ€§èƒ½ä¼˜åŒ–é…ç½®ç¤ºä¾‹

```yaml
# spark-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: spark-config
data:
  spark-defaults.conf: |
    spark.sql.adaptive.enabled=true
    spark.sql.adaptive.coalescePartitions.enabled=true
    spark.sql.adaptive.skewJoin.enabled=true
    spark.serializer=org.apache.spark.serializer.KryoSerializer
    spark.sql.execution.arrow.pyspark.enabled=true
    spark.executor.memory=4g
    spark.executor.cores=2
    spark.driver.memory=2g
    spark.driver.cores=1
```

## æœ€ä½³å®è·µ

### 1. èµ„æºç®¡ç†

- **åˆç†è®¾ç½® Executor æ•°é‡**ï¼šæ ¹æ®é›†ç¾¤èµ„æºå’Œå·¥ä½œè´Ÿè½½è°ƒæ•´
- **ä½¿ç”¨åŠ¨æ€èµ„æºåˆ†é…**ï¼šæ ¹æ®ä»»åŠ¡éœ€æ±‚è‡ªåŠ¨è°ƒæ•´èµ„æº
- **è®¾ç½®èµ„æºé™åˆ¶**ï¼šé¿å…èµ„æºäº‰ç”¨å’Œ OOM é—®é¢˜

### 2. æ•°æ®å­˜å‚¨

- **ä½¿ç”¨æœ¬åœ°å­˜å‚¨**ï¼šæå‡ I/O æ€§èƒ½
- **ä¼˜åŒ–æ•°æ®æ ¼å¼**ï¼šä½¿ç”¨ Parquetã€Delta Lake ç­‰åˆ—å¼å­˜å‚¨
- **æ•°æ®åˆ†åŒºç­–ç•¥**ï¼šåˆç†åˆ†åŒºæå‡æŸ¥è¯¢æ€§èƒ½

### 3. ç›‘æ§å’Œè°ƒä¼˜

- **å¯ç”¨ Spark UI**ï¼šç›‘æ§ä½œä¸šæ‰§è¡Œæƒ…å†µ
- **ä½¿ç”¨ Prometheus ç›‘æ§**ï¼šé›†æˆ Prometheus ç›‘æ§æŒ‡æ ‡
- **å®šæœŸæ€§èƒ½è°ƒä¼˜**ï¼šæ ¹æ®ç›‘æ§æ•°æ®ä¼˜åŒ–é…ç½®

## å®é™…åº”ç”¨æ¡ˆä¾‹

### æ¡ˆä¾‹ 1ï¼šå¤§æ•°æ®æ‰¹å¤„ç†

**åœºæ™¯**ï¼šæ¯å¤©å¤„ç† TB çº§æ•°æ®

**æŠ€æœ¯æ ˆ**ï¼š

- Spark 3.5 on Kubernetes
- Delta Lake å­˜å‚¨
- Prometheus ç›‘æ§

**æ•ˆæœ**ï¼š

- å¤„ç†æ—¶é—´å‡å°‘ 40%
- èµ„æºåˆ©ç”¨ç‡æå‡ 60%
- æˆæœ¬é™ä½ 30%

### æ¡ˆä¾‹ 2ï¼šå®æ—¶æµå¤„ç†

**åœºæ™¯**ï¼šå®æ—¶å¤„ç† Kafka æ•°æ®æµ

**æŠ€æœ¯æ ˆ**ï¼š

- Spark Structured Streaming
- Kubernetes è‡ªåŠ¨æ‰©ç¼©å®¹
- Kafka ä½œä¸ºæ•°æ®æº

**æ•ˆæœ**ï¼š

- å»¶è¿Ÿé™ä½åˆ°ç§’çº§
- è‡ªåŠ¨æ‰©ç¼©å®¹å“åº”æ—¶é—´ < 1 åˆ†é’Ÿ
- 99.9% å¯ç”¨æ€§

## ç›¸å…³æ–‡æ¡£

- [è¯¦ç»†åˆ†ææ–‡æ¡£](../04-domain-case-studies/01-spark-semantic-layering.md)
- [åˆ†å±‚æ¶ˆè§£å¾‹æ¦‚è¿°](../03-layered-disintegration-law/01-introduction.md)
- [åˆ†å¸ƒå¼è®¡ç®—ç³»ç»Ÿæ¶ˆè§£](../03-layered-disintegration-law/02-distributed-computing-disintegration.md)

---

**æœ€åæ›´æ–°**ï¼š2025-11-08 **ç»´æŠ¤è€…**ï¼šé¡¹ç›®å›¢é˜Ÿ
