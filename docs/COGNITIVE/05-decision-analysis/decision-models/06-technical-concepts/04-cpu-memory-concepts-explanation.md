# CPU 与内存概念与技术名词论证

## 📑 目录

- [📑 目录](#-目录)
- [01 文档定位](#01-文档定位)
  - [01.1 文档目标](#011-文档目标)
  - [01.2 文档范围](#012-文档范围)
  - [01.3 与其他文档的关系](#013-与其他文档的关系)
- [02 CPU 拓扑结构](#02-cpu-拓扑结构)
  - [02.1 物理 CPU 拓扑](#021-物理-cpu-拓扑)
    - [02.1.1 物理 CPU 拓扑定义](#0211-物理-cpu-拓扑定义)
    - [02.1.2 物理 CPU 拓扑在技术栈中的作用](#0212-物理-cpu-拓扑在技术栈中的作用)
  - [02.2 逻辑 CPU 拓扑](#022-逻辑-cpu-拓扑)
    - [02.2.1 逻辑 CPU 拓扑定义](#0221-逻辑-cpu-拓扑定义)
    - [02.2.2 逻辑 CPU 拓扑在技术栈中的作用](#0222-逻辑-cpu-拓扑在技术栈中的作用)
  - [02.3 CPU 拓扑映射](#023-cpu-拓扑映射)
    - [02.3.1 物理 CPU 拓扑与逻辑 CPU 拓扑映射](#0231-物理-cpu-拓扑与逻辑-cpu-拓扑映射)
    - [02.3.2 各范式 CPU 拓扑结构映射](#0232-各范式-cpu-拓扑结构映射)
- [03 内存拓扑结构](#03-内存拓扑结构)
  - [03.1 物理内存拓扑](#031-物理内存拓扑)
    - [03.1.1 物理内存拓扑定义](#0311-物理内存拓扑定义)
    - [03.1.2 物理内存拓扑在技术栈中的作用](#0312-物理内存拓扑在技术栈中的作用)
  - [03.2 逻辑内存拓扑](#032-逻辑内存拓扑)
    - [03.2.1 逻辑内存拓扑定义](#0321-逻辑内存拓扑定义)
    - [03.2.2 逻辑内存拓扑在技术栈中的作用](#0322-逻辑内存拓扑在技术栈中的作用)
  - [03.3 内存拓扑映射](#033-内存拓扑映射)
    - [03.3.1 物理内存拓扑与逻辑内存拓扑映射](#0331-物理内存拓扑与逻辑内存拓扑映射)
    - [03.3.2 各范式内存拓扑结构映射](#0332-各范式内存拓扑结构映射)
- [04 CPU 执行模式](#04-cpu-执行模式)
  - [04.1 两级调度模式](#041-两级调度模式)
    - [04.1.1 两级调度模式定义](#0411-两级调度模式定义)
    - [04.1.2 两级调度模式在各范式中的应用](#0412-两级调度模式在各范式中的应用)
  - [04.2 单级调度模式](#042-单级调度模式)
    - [04.2.1 单级调度模式定义](#0421-单级调度模式定义)
    - [04.2.2 单级调度模式在各范式中的应用](#0422-单级调度模式在各范式中的应用)
  - [04.3 应用级调度模式](#043-应用级调度模式)
    - [04.3.1 应用级调度模式定义](#0431-应用级调度模式定义)
    - [04.3.2 应用级调度模式在各范式中的应用](#0432-应用级调度模式在各范式中的应用)
  - [04.4 CPU 执行模式映射](#044-cpu-执行模式映射)
    - [04.4.1 CPU 执行模式对比矩阵](#0441-cpu-执行模式对比矩阵)
    - [04.4.2 各范式 CPU 执行模式映射](#0442-各范式-cpu-执行模式映射)
- [05 内存管理模式](#05-内存管理模式)
  - [05.1 独立物理内存模式](#051-独立物理内存模式)
    - [05.1.1 独立物理内存模式定义](#0511-独立物理内存模式定义)
    - [05.1.2 独立物理内存模式在各范式中的应用](#0512-独立物理内存模式在各范式中的应用)
  - [05.2 共享内核内存模式](#052-共享内核内存模式)
    - [05.2.1 共享内核内存模式定义](#0521-共享内核内存模式定义)
    - [05.2.2 共享内核内存模式在各范式中的应用](#0522-共享内核内存模式在各范式中的应用)
  - [05.3 应用级内存模式](#053-应用级内存模式)
    - [05.3.1 应用级内存模式定义](#0531-应用级内存模式定义)
    - [05.3.2 应用级内存模式在各范式中的应用](#0532-应用级内存模式在各范式中的应用)
  - [05.4 内存管理模式映射](#054-内存管理模式映射)
    - [05.4.1 内存管理模式对比矩阵](#0541-内存管理模式对比矩阵)
    - [05.4.2 各范式内存管理模式映射](#0542-各范式内存管理模式映射)
- [06 CPU 通道模型](#06-cpu-通道模型)
  - [06.1 物理 CPU 通道](#061-物理-cpu-通道)
    - [06.1.1 物理 CPU 通道定义](#0611-物理-cpu-通道定义)
    - [06.1.2 物理 CPU 通道在技术栈中的作用](#0612-物理-cpu-通道在技术栈中的作用)
  - [06.2 逻辑 CPU 通道](#062-逻辑-cpu-通道)
    - [06.2.1 逻辑 CPU 通道定义](#0621-逻辑-cpu-通道定义)
    - [06.2.2 逻辑 CPU 通道在技术栈中的作用](#0622-逻辑-cpu-通道在技术栈中的作用)
  - [06.3 CPU 通道映射](#063-cpu-通道映射)
    - [06.3.1 物理 CPU 通道与逻辑 CPU 通道映射](#0631-物理-cpu-通道与逻辑-cpu-通道映射)
    - [06.3.2 各范式 CPU 通道模型映射](#0632-各范式-cpu-通道模型映射)
- [07 内存通道模型](#07-内存通道模型)
  - [07.1 物理内存通道](#071-物理内存通道)
    - [07.1.1 物理内存通道定义](#0711-物理内存通道定义)
    - [07.1.2 物理内存通道在技术栈中的作用](#0712-物理内存通道在技术栈中的作用)
  - [07.2 逻辑内存通道](#072-逻辑内存通道)
    - [07.2.1 逻辑内存通道定义](#0721-逻辑内存通道定义)
    - [07.2.2 逻辑内存通道在技术栈中的作用](#0722-逻辑内存通道在技术栈中的作用)
  - [07.3 内存通道映射](#073-内存通道映射)
    - [07.3.1 物理内存通道与逻辑内存通道映射](#0731-物理内存通道与逻辑内存通道映射)
    - [07.3.2 各范式内存通道模型映射](#0732-各范式内存通道模型映射)
- [08 CPU 设备模型](#08-cpu-设备模型)
  - [08.1 物理 CPU](#081-物理-cpu)
    - [08.1.1 物理 CPU 定义](#0811-物理-cpu-定义)
    - [08.1.2 物理 CPU 在技术栈中的作用](#0812-物理-cpu-在技术栈中的作用)
  - [08.2 虚拟 CPU (vCPU)](#082-虚拟-cpu-vcpu)
    - [08.2.1 虚拟 CPU 定义](#0821-虚拟-cpu-定义)
    - [08.2.2 虚拟 CPU 在技术栈中的作用](#0822-虚拟-cpu-在技术栈中的作用)
  - [08.3 逻辑 CPU](#083-逻辑-cpu)
    - [08.3.1 逻辑 CPU 定义](#0831-逻辑-cpu-定义)
    - [08.3.2 逻辑 CPU 在技术栈中的作用](#0832-逻辑-cpu-在技术栈中的作用)
  - [08.4 CPU 设备模型映射](#084-cpu-设备模型映射)
    - [08.4.1 CPU 设备模型对比矩阵](#0841-cpu-设备模型对比矩阵)
    - [08.4.2 各范式 CPU 设备模型映射](#0842-各范式-cpu-设备模型映射)
- [09 内存设备模型](#09-内存设备模型)
  - [09.1 物理内存](#091-物理内存)
    - [09.1.1 物理内存定义](#0911-物理内存定义)
    - [09.1.2 物理内存在技术栈中的作用](#0912-物理内存在技术栈中的作用)
  - [09.2 虚拟内存](#092-虚拟内存)
    - [09.2.1 虚拟内存定义](#0921-虚拟内存定义)
    - [09.2.2 虚拟内存在技术栈中的作用](#0922-虚拟内存在技术栈中的作用)
  - [09.3 逻辑内存](#093-逻辑内存)
    - [09.3.1 逻辑内存定义](#0931-逻辑内存定义)
    - [09.3.2 逻辑内存在技术栈中的作用](#0932-逻辑内存在技术栈中的作用)
  - [09.4 内存设备模型映射](#094-内存设备模型映射)
    - [09.4.1 内存设备模型对比矩阵](#0941-内存设备模型对比矩阵)
    - [09.4.2 各范式内存设备模型映射](#0942-各范式内存设备模型映射)
- [10 CPU/内存 协议栈模型](#10-cpu内存-协议栈模型)
  - [10.1 CPU 调度协议栈](#101-cpu-调度协议栈)
    - [10.1.1 物理 CPU 调度协议栈](#1011-物理-cpu-调度协议栈)
    - [10.1.2 虚拟化 CPU 调度协议栈](#1012-虚拟化-cpu-调度协议栈)
    - [10.1.3 容器化 CPU 调度协议栈](#1013-容器化-cpu-调度协议栈)
    - [10.1.4 沙盒化 CPU 调度协议栈](#1014-沙盒化-cpu-调度协议栈)
  - [10.2 内存管理协议栈](#102-内存管理协议栈)
    - [10.2.1 物理内存管理协议栈](#1021-物理内存管理协议栈)
    - [10.2.2 虚拟化内存管理协议栈](#1022-虚拟化内存管理协议栈)
    - [10.2.3 容器化内存管理协议栈](#1023-容器化内存管理协议栈)
    - [10.2.4 沙盒化内存管理协议栈](#1024-沙盒化内存管理协议栈)
  - [10.3 CPU/内存协议栈映射](#103-cpu内存协议栈映射)
    - [10.3.1 CPU/内存协议栈对比矩阵](#1031-cpu内存协议栈对比矩阵)
    - [10.3.2 各范式 CPU/内存协议栈映射](#1032-各范式-cpu内存协议栈映射)
- [11 架构对比分析](#11-架构对比分析)
  - [11.1 CPU/内存架构同构性分析](#111-cpu内存架构同构性分析)
  - [11.2 CPU/内存架构等价性分析](#112-cpu内存架构等价性分析)
  - [11.3 CPU/内存架构性能对比](#113-cpu内存架构性能对比)
  - [11.4 CPU/内存架构安全性对比](#114-cpu内存架构安全性对比)
- [12 总结与展望](#12-总结与展望)
  - [12.1 总结](#121-总结)
  - [12.2 技术趋势与展望](#122-技术趋势与展望)

---

## 01 文档定位

本文档系统地解释和论证虚拟化、容器化、沙盒化三种范式中的 **CPU 与内存**相关的技
术术语、概念、功能、关系和应用场景。

### 01.1 文档目标

1. **概念定义**：清晰定义 CPU 拓扑、内存拓扑、执行模式、管理模式、通道模型、设备
   模型等核心概念
2. **技术论证**：解释各范式如何实现 CPU/内存资源的管理和分配
3. **对比分析**：通过多维矩阵对比三种范式在 CPU/内存方面的异同
4. **架构映射**：分析各范式 CPU/内存架构的同构性和等价性

### 01.2 文档范围

本文档涵盖：

- **CPU 拓扑**：物理 CPU 拓扑、逻辑 CPU 拓扑、SMP/NUMA 架构
- **内存拓扑**：物理内存拓扑、逻辑内存拓扑、内存层次结构
- **执行模式**：两级调度（Hypervisor + Guest OS）、单级调度（Host OS）、应用级调
  度（Runtime）
- **管理模式**：独立物理内存、共享内核内存、应用级内存管理
- **通道模型**：CPU 总线、内存总线、缓存层次、NUMA 互连
- **设备模型**：物理 CPU/vCPU、物理内存/虚拟内存、逻辑资源抽象

### 01.3 与其他文档的关系

- **网络概念论证**：说明网络层面如何与 CPU/内存交互（如网络中断处理、零拷贝）
- **存储概念论证**：说明存储层面如何与 CPU/内存交互（如直接内存访问 DMA）
- **技术概念解释**：作为技术概念论证文档的组成部分，专注 CPU/内存维度
- **资源模型文档**：与数学化的资源模型对应，提供技术实现层面的解释

---

## 02 CPU 拓扑结构

### 02.1 物理 CPU 拓扑

#### 02.1.1 物理 CPU 拓扑定义

**物理 CPU 拓扑（Physical CPU Topology）定义**：

物理 CPU 拓扑是指 CPU 核心、缓存层次、NUMA 节点在物理硬件上的实际布局和连接关系
。

**物理 CPU 拓扑类型**：

1. **SMP 架构（Symmetric Multiprocessing）**：

   - **结构**：多个 CPU 核心通过统一的总线访问共享内存
   - **特征**：对称访问、统一内存视图、缓存一致性协议（MESI）
   - **应用**：单路、双路服务器、桌面 CPU

2. **NUMA 架构（Non-Uniform Memory Access）**：

   - **结构**：多个 CPU 节点，每个节点有本地内存，通过互连访问远程内存
   - **特征**：非对称访问、本地内存延迟低、远程内存延迟高
   - **应用**：多路服务器、高性能计算（HPC）

3. **缓存层次结构（Cache Hierarchy）**：

   - **L1 Cache**：指令缓存（I-Cache）、数据缓存（D-Cache），每核心私有
   - **L2 Cache**：统一缓存，每核心私有或共享
   - **L3 Cache**：最后一级缓存（LLC），多核心共享
   - **特征**：延迟递增（L1 < L2 < L3 < 内存）、容量递增

#### 02.1.2 物理 CPU 拓扑在技术栈中的作用

**物理 CPU 拓扑映射**：

```text
物理 CPU 拓扑结构:

SMP 架构:
├── CPU Socket 0
│   ├── CPU Core 0
│   │   ├── L1 I-Cache
│   │   ├── L1 D-Cache
│   │   └── L2 Cache
│   ├── CPU Core 1
│   │   ├── L1 I-Cache
│   │   ├── L1 D-Cache
│   │   └── L2 Cache
│   └── L3 Cache (共享)
├── 内存控制器 (Unified Memory Controller)
└── 共享物理内存

NUMA 架构:
├── NUMA Node 0
│   ├── CPU Socket 0
│   │   ├── CPU Cores (0-15)
│   │   ├── L1/L2/L3 Cache
│   │   └── 本地内存 (Local Memory)
│   └── 本地内存控制器
├── NUMA Node 1
│   ├── CPU Socket 1
│   │   ├── CPU Cores (16-31)
│   │   ├── L1/L2/L3 Cache
│   │   └── 本地内存 (Local Memory)
│   └── 本地内存控制器
└── NUMA 互连 (NUMA Interconnect)
    ├── QPI (Intel)
    ├── HyperTransport (AMD)
    └── Infinity Fabric (AMD EPYC)
```

**物理 CPU 拓扑特性**：

| 特性         | SMP              | NUMA                   |
| ------------ | ---------------- | ---------------------- |
| 内存访问延迟 | 统一延迟         | 本地低延迟、远程高延迟 |
| 可扩展性     | 受限（总线带宽） | 高（分布式架构）       |
| 内存一致性   | 全局一致性       | 缓存一致性协议         |
| 典型应用     | 2-4 路服务器     | 4+ 路服务器、HPC       |
| CPU 核心数   | 2-32 核心        | 32-256+ 核心           |

### 02.2 逻辑 CPU 拓扑

#### 02.2.1 逻辑 CPU 拓扑定义

**逻辑 CPU 拓扑（Logical CPU Topology）定义**：

逻辑 CPU 拓扑是指操作系统或虚拟化层对 CPU 资源的逻辑抽象和映射关系，独立于物理硬
件布局。

**逻辑 CPU 拓扑类型**：

1. **CPU 亲和性（CPU Affinity）**：

   - **结构**：将进程/线程绑定到特定 CPU 核心
   - **特征**：避免上下文切换、提高缓存命中率、减少 NUMA 跨节点访问
   - **应用**：高性能应用、实时系统、数据库

2. **CPU 集（CPU Set/Cpuset）**：

   - **结构**：逻辑上划分 CPU 核心集合，分配给特定任务组
   - **特征**：资源隔离、动态分配、层级管理
   - **应用**：容器资源限制、虚拟化 vCPU 分配

3. **CPU 调度域（Scheduling Domain）**：

   - **结构**：根据 CPU 拓扑划分调度层级（Socket → Core → Thread）
   - **特征**：负载均衡、功耗管理、NUMA 感知调度
   - **应用**：Linux CFS 调度器、虚拟化调度

#### 02.2.2 逻辑 CPU 拓扑在技术栈中的作用

**逻辑 CPU 拓扑映射**：

```text
逻辑 CPU 拓扑结构:

操作系统逻辑拓扑:
├── CPU 调度域 (Scheduling Domain)
│   ├── NUMA 域 (NUMA Domain)
│   │   ├── CPU Socket 逻辑映射
│   │   ├── CPU Core 逻辑映射
│   │   └── CPU Thread 逻辑映射 (SMT/HT)
│   └── CPU 亲和性 (CPU Affinity)
├── CPU 集 (Cpuset)
│   ├── cgroup cpuset
│   ├── 容器 CPU 限制
│   └── 虚拟化 vCPU 分配
└── CPU 调度策略
    ├── CFS (Completely Fair Scheduler)
    ├── RT (Real-Time Scheduler)
    └── Deadline Scheduler

虚拟化逻辑拓扑:
├── vCPU 映射到物理 CPU
│   ├── 静态绑定 (CPU Pinning)
│   ├── 动态调度 (Hypervisor Scheduler)
│   └── NUMA 感知调度
└── vCPU 拓扑暴露
    ├── vCPU Socket 配置
    ├── vCPU Core 配置
    └── vCPU Thread 配置 (SMT/HT)
```

### 02.3 CPU 拓扑映射

#### 02.3.1 物理 CPU 拓扑与逻辑 CPU 拓扑映射

**映射关系**：

```text
物理 CPU 拓扑 → 逻辑 CPU 拓扑映射:

物理层:
NUMA Node 0
├── Socket 0 (物理)
│   ├── Core 0 (物理)
│   │   ├── Thread 0 (物理) → CPU 0
│   │   └── Thread 1 (物理) → CPU 1
│   └── Core 1 (物理)
│       ├── Thread 0 (物理) → CPU 2
│       └── Thread 1 (物理) → CPU 3
└── 本地内存

逻辑层:
├── 操作系统视图
│   ├── CPU 0-3 (逻辑 CPU)
│   ├── CPU 调度域识别 NUMA 节点
│   └── CPU 亲和性映射到物理核心
└── 虚拟化视图
    ├── vCPU 0 → 物理 CPU 0-3 (动态调度)
    ├── vCPU 1 → 物理 CPU 0-3 (动态调度)
    └── NUMA 拓扑暴露给 Guest OS
```

#### 02.3.2 各范式 CPU 拓扑结构映射

**各范式 CPU 拓扑映射矩阵**：

| 维度              | 虚拟化                                 | 容器化                       | 沙盒化                   |
| ----------------- | -------------------------------------- | ---------------------------- | ------------------------ |
| **物理 CPU 拓扑** | 直接访问（Type-1）或间接访问（Type-2） | 直接访问                     | 直接访问                 |
| **逻辑 CPU 拓扑** | Guest OS 独立逻辑拓扑                  | Host OS 共享逻辑拓扑         | Runtime 逻辑拓扑         |
| **CPU 抽象**      | vCPU (虚拟 CPU)                        | cgroup CPU 限制              | Wasm Runtime 线程        |
| **CPU 调度**      | Hypervisor 两级调度                    | Host OS 单级调度             | Runtime 应用级调度       |
| **NUMA 感知**     | 支持（NUMA 拓扑暴露）                  | 支持（NUMA 感知调度）        | 有限（Runtime 抽象）     |
| **CPU 亲和性**    | 支持（vCPU Pinning）                   | 支持（cpuset）               | 有限（Runtime 线程绑定） |
| **SMT/HT 支持**   | 支持（暴露超线程）                     | 支持（操作系统管理）         | 有限（Runtime 抽象）     |
| **缓存感知**      | 有限（Guest OS 感知）                  | 支持（Host OS 缓存感知调度） | 有限（Runtime 抽象）     |

---

## 03 内存拓扑结构

### 03.1 物理内存拓扑

#### 03.1.1 物理内存拓扑定义

**物理内存拓扑（Physical Memory Topology）定义**：

物理内存拓扑是指物理内存模块（DIMM）、内存控制器、内存通道在硬件上的实际布局和连
接关系。

**物理内存拓扑类型**：

1. **统一内存架构（UMA - Uniform Memory Architecture）**：

   - **结构**：所有内存通过统一的内存控制器访问
   - **特征**：统一访问延迟、对称内存访问
   - **应用**：SMP 系统、桌面系统

2. **非统一内存架构（NUMA - Non-Uniform Memory Access）**：

   - **结构**：每个 NUMA 节点有本地内存，通过互连访问远程内存
   - **特征**：本地内存低延迟、远程内存高延迟、带宽不对称
   - **应用**：多路服务器、HPC 系统

3. **内存层次结构（Memory Hierarchy）**：

   - **L1 Cache**：每核心私有，延迟 ~1ns
   - **L2 Cache**：每核心私有或共享，延迟 ~3-10ns
   - **L3 Cache**：多核心共享，延迟 ~20-40ns
   - **内存（DRAM）**：延迟 ~50-100ns，带宽 20-100+ GB/s
   - **持久内存（PMEM）**：延迟 ~200-300ns，容量大，非易失性

#### 03.1.2 物理内存拓扑在技术栈中的作用

**物理内存拓扑映射**：

```text
物理内存拓扑结构:

UMA 架构:
├── 统一内存控制器 (UIMC)
├── 内存通道 (Memory Channels)
│   ├── Channel 0: DIMM 0-3
│   ├── Channel 1: DIMM 0-3
│   └── Channel 2: DIMM 0-3
└── 共享物理内存
    ├── DDR4/DDR5 DIMM
    └── 访问延迟统一

NUMA 架构:
├── NUMA Node 0
│   ├── 本地内存控制器
│   ├── 内存通道
│   │   ├── Channel 0: DIMM 0-3
│   │   ├── Channel 1: DIMM 0-3
│   │   └── Channel 2: DIMM 0-3
│   └── 本地内存 (Local Memory)
│       ├── 访问延迟: ~50ns
│       └── 带宽: ~50-100 GB/s
├── NUMA Node 1
│   ├── 本地内存控制器
│   ├── 内存通道
│   └── 本地内存 (Local Memory)
└── NUMA 互连
    ├── 远程内存访问 (Remote Memory)
    ├── 访问延迟: ~100-200ns
    └── 带宽: ~20-50 GB/s
```

**物理内存拓扑特性**：

| 特性         | UMA          | NUMA                   |
| ------------ | ------------ | ---------------------- |
| 内存访问延迟 | 统一延迟     | 本地低延迟、远程高延迟 |
| 内存带宽     | 受总线限制   | 分布式带宽、可扩展     |
| 内存容量扩展 | 受限         | 高（多节点）           |
| 内存一致性   | 全局一致性   | 缓存一致性协议         |
| 典型应用     | 2-4 路服务器 | 4+ 路服务器、HPC       |

### 03.2 逻辑内存拓扑

#### 03.2.1 逻辑内存拓扑定义

**逻辑内存拓扑（Logical Memory Topology）定义**：

逻辑内存拓扑是指操作系统或虚拟化层对内存资源的逻辑抽象和映射关系，包括虚拟内存、
页表、内存节点等。

**逻辑内存拓扑类型**：

1. **虚拟内存空间（Virtual Address Space）**：

   - **结构**：每个进程有独立的虚拟地址空间（32 位：4GB，64 位：128TB+）
   - **特征**：地址空间隔离、按需分配、页式管理
   - **应用**：进程隔离、内存保护

2. **内存节点（Memory Node）**：

   - **结构**：操作系统识别物理内存节点（NUMA 节点）
   - **特征**：NUMA 感知分配、内存策略（local/prefer local/interleave）
   - **应用**：NUMA 优化、内存本地性

3. **内存区域（Memory Zone）**：

   - **DMA Zone**：直接内存访问区域（<16MB）
   - **Normal Zone**：普通内存区域（16MB-896MB）
   - **HighMem Zone**：高端内存区域（>896MB，32 位系统）
   - **Movable Zone**：可移动内存区域（用于内存压缩）

#### 03.2.2 逻辑内存拓扑在技术栈中的作用

**逻辑内存拓扑映射**：

```text
逻辑内存拓扑结构:

操作系统逻辑拓扑:
├── 虚拟内存空间
│   ├── 用户空间 (User Space)
│   │   ├── 代码段 (Text)
│   │   ├── 数据段 (Data)
│   │   ├── BSS 段
│   │   ├── 堆 (Heap)
│   │   └── 栈 (Stack)
│   └── 内核空间 (Kernel Space)
├── 物理内存映射
│   ├── 页表 (Page Table)
│   ├── 页帧 (Page Frame)
│   └── 反向映射 (Reverse Mapping)
├── NUMA 内存节点
│   ├── Node 0 (对应物理 NUMA Node 0)
│   ├── Node 1 (对应物理 NUMA Node 1)
│   └── 内存策略
│       ├── MPOL_LOCAL (本地优先)
│       ├── MPOL_PREFERRED (偏好本地)
│       └── MPOL_INTERLEAVE (交错分配)
└── 内存区域 (Memory Zone)
    ├── DMA Zone
    ├── Normal Zone
    └── Movable Zone

虚拟化逻辑拓扑:
├── Guest 物理内存 (GPA - Guest Physical Address)
│   ├── Guest OS 看到的内存地址空间
│   └── 映射到 Host 物理内存 (HPA)
├── 虚拟内存 (GVA - Guest Virtual Address)
│   └── Guest OS 管理的虚拟地址空间
└── 内存映射表
    ├── EPT (Extended Page Table, Intel)
    ├── NPT (Nested Page Table, AMD)
    └── Shadow Page Table (软件虚拟化)
```

### 03.3 内存拓扑映射

#### 03.3.1 物理内存拓扑与逻辑内存拓扑映射

**映射关系**：

```text
物理内存拓扑 → 逻辑内存拓扑映射:

物理层:
NUMA Node 0
├── 本地内存: 64GB
├── 内存控制器
└── CPU Socket 0

NUMA Node 1
├── 本地内存: 64GB
├── 内存控制器
└── CPU Socket 1

逻辑层:
├── 操作系统内存节点
│   ├── Node 0 → 物理 NUMA Node 0
│   └── Node 1 → 物理 NUMA Node 1
├── 虚拟内存映射
│   ├── 进程虚拟地址 → 物理页帧
│   ├── NUMA 本地分配（优先 Node 0）
│   └── NUMA 远程分配（跨节点访问）
└── 内存区域
    ├── Zone DMA
    ├── Zone Normal
    └── Zone Movable
```

#### 03.3.2 各范式内存拓扑结构映射

**各范式内存拓扑映射矩阵**：

| 维度             | 虚拟化                         | 容器化                | 沙盒化                    |
| ---------------- | ------------------------------ | --------------------- | ------------------------- |
| **物理内存拓扑** | 直接访问或间接访问             | 直接访问              | 直接访问                  |
| **逻辑内存拓扑** | Guest OS 独立逻辑拓扑          | Host OS 共享逻辑拓扑  | Runtime 逻辑拓扑          |
| **内存抽象**     | Guest 物理内存 (GPA)           | cgroup 内存限制       | Wasm 线性内存             |
| **内存管理**     | Hypervisor + Guest OS 两级管理 | Host OS 单级管理      | Runtime 应用级管理        |
| **NUMA 感知**    | 支持（NUMA 拓扑暴露）          | 支持（NUMA 感知分配） | 有限（Runtime 抽象）      |
| **内存隔离**     | 硬件级隔离（EPT/NPT）          | 命名空间隔离 + cgroup | 线性内存隔离              |
| **内存共享**     | 不支持（独立物理内存）         | 支持（共享内核内存）  | 支持（共享 Runtime 内存） |
| **内存超分**     | 支持（内存超分/气球驱动）      | 支持（cgroup 限制）   | 支持（Runtime 内存池）    |

---

## 04 CPU 执行模式

### 04.1 两级调度模式

#### 04.1.1 两级调度模式定义

**两级调度模式（Two-Level Scheduling）定义**：

两级调度模式是指在虚拟化环境中，存在 Hypervisor 层和 Guest OS 层两级 CPU 调度机
制。

**两级调度模式特征**：

1. **Hypervisor 层调度**：

   - **结构**：Hypervisor 调度器负责将 vCPU 调度到物理 CPU 上
   - **特征**：vCPU → 物理 CPU 映射、时间片分配、NUMA 感知调度
   - **调度算法**：Credit Scheduler（Xen）、ESX Scheduler（VMware）

2. **Guest OS 层调度**：

   - **结构**：Guest OS 调度器负责在 vCPU 上调度进程/线程
   - **特征**：进程/线程 → vCPU 映射、Guest OS 调度策略
   - **调度算法**：CFS（Linux Guest）、Windows Scheduler

3. **两级调度开销**：

   - **上下文切换**：Guest OS 上下文切换 + Hypervisor 上下文切换
   - **调度延迟**：两级调度延迟叠加
   - **CPU 利用率**：两级调度器开销

#### 04.1.2 两级调度模式在各范式中的应用

**虚拟化两级调度**：

```text
虚拟化两级调度:

Hypervisor 层:
├── vCPU 调度器
│   ├── vCPU 0 → 物理 CPU 0-3 (动态调度)
│   ├── vCPU 1 → 物理 CPU 0-3 (动态调度)
│   └── vCPU 2 → 物理 CPU 4-7 (动态调度)
├── 调度策略
│   ├── 抢占式调度
│   ├── 时间片分配
│   └── NUMA 感知调度
└── 调度开销
    ├── vCPU 上下文切换
    └── 两级调度延迟

Guest OS 层:
├── 进程/线程调度器
│   ├── 进程 A → vCPU 0
│   ├── 进程 B → vCPU 0
│   └── 线程 C → vCPU 1
├── Guest OS 调度策略
│   ├── CFS (Linux)
│   ├── Windows Scheduler
│   └── 实时调度
└── 调度开销
    ├── 进程上下文切换
    └── Guest OS 调度开销

两级调度开销:
├── Guest OS 上下文切换开销
├── Hypervisor 上下文切换开销
└── 总调度延迟 = Guest OS 延迟 + Hypervisor 延迟
```

**两级调度性能影响**：

| 维度               | 虚拟化两级调度                         |
| ------------------ | -------------------------------------- |
| **调度延迟**       | 高（两级调度延迟叠加）                 |
| **上下文切换开销** | 高（Guest OS + Hypervisor 上下文切换） |
| **CPU 利用率**     | 降低（两级调度器开销）                 |
| **NUMA 感知**      | 支持（Hypervisor NUMA 感知调度）       |
| **实时性**         | 有限（两级调度延迟）                   |

### 04.2 单级调度模式

#### 04.2.1 单级调度模式定义

**单级调度模式（Single-Level Scheduling）定义**：

单级调度模式是指容器化环境中，只有 Host OS 一层 CPU 调度机制。

**单级调度模式特征**：

1. **Host OS 层调度**：

   - **结构**：Host OS 调度器直接调度容器进程到物理 CPU
   - **特征**：进程 → 物理 CPU 映射、时间片分配、NUMA 感知调度
   - **调度算法**：CFS（Linux Host）、实时调度

2. **cgroup CPU 限制**：

   - **结构**：cgroup CPU 控制器限制容器 CPU 使用
   - **特征**：CPU 份额（cpu.shares）、CPU 配额（cpu.cfs_quota_us）、CPU 集合
     （cpuset）
   - **应用**：容器资源限制、多租户隔离

3. **单级调度优势**：

   - **上下文切换**：只有 Host OS 上下文切换
   - **调度延迟**：单级调度延迟，更低
   - **CPU 利用率**：单级调度器开销，更高

#### 04.2.2 单级调度模式在各范式中的应用

**容器化单级调度**：

```text
容器化单级调度:

Host OS 层:
├── 进程调度器
│   ├── Container A 进程 → 物理 CPU 0-3
│   ├── Container B 进程 → 物理 CPU 4-7
│   └── Container C 进程 → 物理 CPU 0-7
├── 调度策略
│   ├── CFS (Completely Fair Scheduler)
│   ├── RT (Real-Time Scheduler)
│   └── Deadline Scheduler
├── cgroup CPU 限制
│   ├── cpu.shares (CPU 份额)
│   ├── cpu.cfs_quota_us (CPU 配额)
│   └── cpuset (CPU 集合)
└── 调度开销
    ├── 进程上下文切换
    └── 单级调度延迟

Container 层:
├── 共享 Host OS CPU 调度
├── 受 cgroup 限制的 CPU 资源
└── 应用感知实际 CPU 拓扑

单级调度优势:
├── 调度延迟低（单级调度）
├── 上下文切换开销低（只有 Host OS）
└── CPU 利用率高（单级调度器开销）
```

**单级调度性能影响**：

| 维度               | 容器化单级调度                |
| ------------------ | ----------------------------- |
| **调度延迟**       | 低（单级调度延迟）            |
| **上下文切换开销** | 低（只有 Host OS 上下文切换） |
| **CPU 利用率**     | 高（单级调度器开销）          |
| **NUMA 感知**      | 支持（Host OS NUMA 感知调度） |
| **实时性**         | 好（单级调度延迟低）          |

### 04.3 应用级调度模式

#### 04.3.1 应用级调度模式定义

**应用级调度模式（Application-Level Scheduling）定义**：

应用级调度模式是指沙盒化环境中，Wasm Runtime 在应用层进行线程调度和 CPU 资源管理
。

**应用级调度模式特征**：

1. **Runtime 层调度**：

   - **结构**：Wasm Runtime 使用线程池模型进行任务调度
   - **特征**：工作线程（Worker Threads）、协程调度、事件循环
   - **调度算法**：Runtime 内部调度策略

2. **Host OS 层调度**：

   - **结构**：Host OS 调度 Runtime 线程到物理 CPU
   - **特征**：Runtime 线程 → 物理 CPU 映射
   - **调度算法**：Host OS 调度器（CFS）

3. **应用级调度特点**：

   - **抽象层次**：完全隐藏物理 CPU 拓扑
   - **调度粒度**：Wasm 函数/模块级别
   - **CPU 限制**：Runtime 线程数限制

#### 04.3.2 应用级调度模式在各范式中的应用

**沙盒化应用级调度**：

```text
沙盒化应用级调度:

Host OS 层:
├── 线程调度器
│   ├── Runtime Worker Thread 0 → 物理 CPU 0-7
│   ├── Runtime Worker Thread 1 → 物理 CPU 0-7
│   └── Runtime Main Thread → 物理 CPU 0-7
├── 调度策略
│   └── Host OS 调度器 (CFS)
└── 调度开销
    └── 线程上下文切换

Wasm Runtime 层:
├── 线程池模型
│   ├── 工作线程池 (Worker Thread Pool)
│   ├── 任务队列 (Task Queue)
│   └── 任务调度 (Task Scheduling)
├── Wasm 模块调度
│   ├── Wasm 函数执行
│   ├── 异步任务调度
│   └── 事件循环 (Event Loop)
├── CPU 资源限制
│   ├── 线程数限制
│   └── CPU 时间限制（可选）
└── 调度开销
    ├── Wasm 函数调用开销
    └── Runtime 内部调度开销

Wasm 应用层:
├── 线性内存 (Linear Memory)
├── 函数执行 (基于 Wasm 指令)
└── 不感知 CPU 拓扑（完全抽象）

应用级调度特点:
├── 抽象层次高（完全隐藏物理 CPU）
├── 调度粒度细（Wasm 函数级别）
└── CPU 限制粗（Runtime 线程级别）
```

**应用级调度性能影响**：

| 维度               | 沙盒化应用级调度                          |
| ------------------ | ----------------------------------------- |
| **调度延迟**       | 中等（Runtime 调度 + Host OS 调度）       |
| **上下文切换开销** | 中等（Runtime 开销 + Host OS 上下文切换） |
| **CPU 利用率**     | 中等（Runtime 开销 + Host OS 调度开销）   |
| **NUMA 感知**      | 有限（Runtime 抽象，Host OS NUMA 感知）   |
| **实时性**         | 中等（Runtime 调度延迟）                  |

### 04.4 CPU 执行模式映射

#### 04.4.1 CPU 执行模式对比矩阵

**CPU 执行模式对比矩阵**：

| 维度               | 两级调度模式                | 单级调度模式         | 应用级调度模式            |
| ------------------ | --------------------------- | -------------------- | ------------------------- |
| **调度层级**       | Hypervisor + Guest OS       | Host OS              | Runtime + Host OS         |
| **调度延迟**       | 高（两级延迟叠加）          | 低（单级延迟）       | 中等（Runtime + Host OS） |
| **上下文切换开销** | 高（Guest OS + Hypervisor） | 低（只有 Host OS）   | 中等（Runtime + Host OS） |
| **CPU 利用率**     | 低（两级调度器开销）        | 高（单级调度器开销） | 中等（Runtime + Host OS） |
| **NUMA 感知**      | 支持（Hypervisor 感知）     | 支持（Host OS 感知） | 有限（Runtime 抽象）      |
| **实时性**         | 有限（两级调度延迟）        | 好（单级调度延迟低） | 中等（Runtime 调度延迟）  |
| **CPU 抽象**       | vCPU                        | cgroup CPU 限制      | Runtime 线程              |
| **典型应用**       | 虚拟化                      | 容器化               | 沙盒化                    |

#### 04.4.2 各范式 CPU 执行模式映射

**各范式 CPU 执行模式架构**：

```text
各范式 CPU 执行模式架构对比:

虚拟化（两级调度）:
物理 CPU
  ↓
Hypervisor Scheduler (vCPU 调度)
  ↓
vCPU (虚拟 CPU)
  ↓
Guest OS Scheduler (进程调度)
  ↓
进程/线程

容器化（单级调度）:
物理 CPU
  ↓
Host OS Scheduler (进程调度)
  ↓
Container 进程
  ↓
cgroup CPU 限制

沙盒化（应用级调度）:
物理 CPU
  ↓
Host OS Scheduler (线程调度)
  ↓
Runtime Worker Thread
  ↓
Runtime Scheduler (任务调度)
  ↓
Wasm 函数/模块
```

---

## 05 内存管理模式

### 05.1 独立物理内存模式

#### 05.1.1 独立物理内存模式定义

**独立物理内存模式（Independent Physical Memory）定义**：

独立物理内存模式是指虚拟化环境中，每个虚拟机拥有独立的 Guest 物理内存空间，通过
EPT/NPT 硬件机制映射到 Host 物理内存。

**独立物理内存模式特征**：

1. **Guest 物理内存（GPA - Guest Physical Address）**：

   - **结构**：Guest OS 看到的内存地址空间，独立于其他虚拟机
   - **特征**：独立地址空间、硬件级隔离、EPT/NPT 映射
   - **应用**：虚拟机内存隔离、安全隔离

2. **硬件内存虚拟化**：

   - **EPT（Extended Page Table, Intel）**：硬件加速的二级页表转换
   - **NPT（Nested Page Table, AMD）**：硬件加速的嵌套页表转换
   - **特征**：GVA → GPA → HPA 三级地址转换、硬件加速、低开销

3. **内存超分（Memory Overcommit）**：

   - **结构**：分配的 Guest 物理内存总量可以超过 Host 物理内存
   - **特征**：按需分配、内存交换、内存压缩、内存气球驱动
   - **应用**：提高内存利用率、多虚拟机场景

#### 05.1.2 独立物理内存模式在各范式中的应用

**虚拟化独立物理内存**：

```text
虚拟化独立物理内存模式:

Host 物理内存 (HPA):
├── VM1 Guest 物理内存映射 (GPA → HPA)
│   ├── 通过 EPT/NPT 映射
│   ├── Guest OS 虚拟地址 (GVA) → Guest 物理地址 (GPA)
│   └── Guest 物理地址 (GPA) → Host 物理地址 (HPA)
├── VM2 Guest 物理内存映射 (GPA → HPA)
│   └── 独立地址空间
└── VM3 Guest 物理内存映射 (GPA → HPA)
    └── 独立地址空间

内存隔离:
├── 硬件级隔离 (EPT/NPT)
├── Guest 物理内存空间独立
└── 虚拟机间内存完全隔离

内存超分:
├── 内存气球驱动 (Memory Balloon)
│   ├── 动态回收虚拟机内存
│   └── 将内存返还给 Hypervisor
├── 内存交换 (Memory Swapping)
│   └── 将 Guest 物理内存交换到磁盘
└── 内存压缩 (Memory Compression)
    └── 压缩空闲内存页
```

**独立物理内存模式特点**：

| 维度               | 独立物理内存模式                         |
| ------------------ | ---------------------------------------- |
| **内存隔离**       | 硬件级隔离（EPT/NPT），完全隔离          |
| **内存共享**       | 不支持（独立物理内存空间）               |
| **内存超分**       | 支持（内存超分、交换、压缩、气球驱动）   |
| **地址转换开销**   | 中等（EPT/NPT 硬件加速，但三级地址转换） |
| **内存管理灵活性** | 高（Hypervisor + Guest OS 两级管理）     |
| **NUMA 感知**      | 支持（NUMA 拓扑暴露给 Guest OS）         |
| **典型应用**       | 虚拟化                                   |

### 05.2 共享内核内存模式

#### 05.2.1 共享内核内存模式定义

**共享内核内存模式（Shared Kernel Memory）定义**：

共享内核内存模式是指容器化环境中，多个容器共享同一个 Host OS 内核内存空间，每个
容器通过命名空间和 cgroup 进行内存隔离和限制。

**共享内核内存模式特征**：

1. **共享内核内存**：

   - **结构**：所有容器共享 Host OS 内核内存空间
   - **特征**：内核内存共享、用户空间隔离、命名空间隔离
   - **应用**：容器内存共享、高内存利用率

2. **命名空间内存隔离**：

   - **PID 命名空间**：进程 ID 隔离
   - **Mount 命名空间**：文件系统隔离
   - **IPC 命名空间**：进程间通信隔离
   - **特征**：逻辑隔离、不提供硬件级隔离

3. **cgroup 内存限制**：

   - **memory.limit_in_bytes**：内存限制（硬限制）
   - **memory.soft_limit_in_bytes**：内存软限制
   - **memory.oom_control**：OOM 控制
   - **特征**：资源限制、OOM 防护、内存统计

#### 05.2.2 共享内核内存模式在各范式中的应用

**容器化共享内核内存**：

```text
容器化共享内核内存模式:

Host OS 内存空间:
├── 内核内存 (共享)
│   ├── 内核代码段
│   ├── 内核数据段
│   ├── 内核栈
│   └── 所有容器共享
├── Container A 用户空间
│   ├── 进程虚拟地址空间
│   ├── cgroup 内存限制
│   └── 命名空间隔离
├── Container B 用户空间
│   ├── 进程虚拟地址空间
│   ├── cgroup 内存限制
│   └── 命名空间隔离
└── Container C 用户空间
    ├── 进程虚拟地址空间
    ├── cgroup 内存限制
    └── 命名空间隔离

内存共享:
├── 内核内存共享（代码、数据、缓存）
├── 共享库共享（如 glibc、libc.so）
└── 页缓存共享（文件系统缓存）

内存隔离:
├── 用户空间内存隔离（进程虚拟地址空间）
├── 命名空间隔离（逻辑隔离）
└── cgroup 内存限制（资源限制）
```

**共享内核内存模式特点**：

| 维度               | 共享内核内存模式                            |
| ------------------ | ------------------------------------------- |
| **内存隔离**       | 命名空间 + cgroup（逻辑隔离，非硬件级）     |
| **内存共享**       | 支持（共享内核内存、共享库、页缓存）        |
| **内存超分**       | 支持（cgroup 限制，但共享内核内存）         |
| **地址转换开销**   | 低（只有二级地址转换：虚拟地址 → 物理地址） |
| **内存管理灵活性** | 中等（Host OS 单级管理）                    |
| **NUMA 感知**      | 支持（Host OS NUMA 感知分配）               |
| **典型应用**       | 容器化                                      |

### 05.3 应用级内存模式

#### 05.3.1 应用级内存模式定义

**应用级内存模式（Application-Level Memory）定义**：

应用级内存模式是指沙盒化环境中，Wasm Runtime 在应用层管理线性内存（Linear
Memory），提供应用级内存抽象和隔离。

**应用级内存模式特征**：

1. **线性内存（Linear Memory）**：

   - **结构**：单一片连续的地址空间，从 0 开始的线性地址
   - **特征**：单一片连续内存、大小可动态增长（最大 4GB）、地址从 0 开始
   - **应用**：Wasm 模块内存管理、应用数据存储

2. **零 RootFS 模型**：

   - **结构**：Wasm 模块不包含文件系统，只有线性内存
   - **特征**：无文件系统开销、轻量级、快速启动
   - **应用**：Serverless 函数、边缘计算

3. **内存隔离**：

   - **Wasm 模块间隔离**：每个 Wasm 模块有独立的线性内存
   - **Host 内存隔离**：Wasm 内存与 Host 内存隔离
   - **特征**：应用级隔离、类型安全、边界检查

#### 05.3.2 应用级内存模式在各范式中的应用

**沙盒化应用级内存**：

```text
沙盒化应用级内存模式:

Host OS 内存空间:
├── Host OS 进程内存空间
│   ├── Runtime 进程虚拟地址空间
│   └── Host OS 内存管理
└── Runtime 内存池
    ├── Wasm Module A 线性内存
    │   ├── 从 0 开始的线性地址
    │   ├── 单一片连续内存
    │   └── 大小可动态增长（最大 4GB）
    ├── Wasm Module B 线性内存
    │   └── 独立线性内存
    └── Wasm Module C 线性内存
        └── 独立线性内存

内存抽象:
├── 线性内存模型（完全隐藏物理内存拓扑）
├── 零 RootFS（无文件系统）
└── 应用级内存管理（Runtime 内存池）

内存隔离:
├── Wasm 模块间内存隔离
├── Wasm 内存与 Host 内存隔离
└── 类型安全、边界检查

内存操作:
├── load（从线性内存加载数据）
├── store（向线性内存存储数据）
└── memory.grow（扩展线性内存大小）
```

**应用级内存模式特点**：

| 维度               | 应用级内存模式                             |
| ------------------ | ------------------------------------------ |
| **内存隔离**       | 应用级隔离（线性内存隔离、类型安全）       |
| **内存共享**       | 支持（Runtime 内存池，但 Wasm 模块间隔离） |
| **内存超分**       | 支持（Runtime 内存池动态分配）             |
| **地址转换开销**   | 低（Runtime 内部映射，简单线性内存）       |
| **内存管理灵活性** | 中等（Runtime 应用级管理）                 |
| **NUMA 感知**      | 有限（Runtime 抽象，Host OS NUMA 感知）    |
| **典型应用**       | 沙盒化（Wasm）                             |

### 05.4 内存管理模式映射

#### 05.4.1 内存管理模式对比矩阵

**内存管理模式对比矩阵**：

| 维度             | 独立物理内存模式                             | 共享内核内存模式                     | 应用级内存模式                          |
| ---------------- | -------------------------------------------- | ------------------------------------ | --------------------------------------- |
| **内存抽象**     | Guest 物理内存 (GPA)                         | Host OS 虚拟地址空间                 | Wasm 线性内存                           |
| **内存隔离**     | 硬件级隔离（EPT/NPT）                        | 命名空间 + cgroup（逻辑隔离）        | 应用级隔离（线性内存隔离）              |
| **内存共享**     | 不支持（独立物理内存空间）                   | 支持（共享内核内存、共享库、页缓存） | 支持（Runtime 内存池，但模块间隔离）    |
| **内存管理**     | Hypervisor + Guest OS 两级管理               | Host OS 单级管理                     | Runtime 应用级管理                      |
| **内存超分**     | 支持（内存超分、交换、压缩、气球驱动）       | 支持（cgroup 限制，但共享内核内存）  | 支持（Runtime 内存池动态分配）          |
| **地址转换开销** | 中等（GVA → GPA → HPA 三级转换，但硬件加速） | 低（虚拟地址 → 物理地址 二级转换）   | 低（Runtime 内部映射，简单线性内存）    |
| **NUMA 感知**    | 支持（NUMA 拓扑暴露给 Guest OS）             | 支持（Host OS NUMA 感知分配）        | 有限（Runtime 抽象，Host OS NUMA 感知） |
| **内存开销**     | 高（Guest OS 内存开销）                      | 低（共享内核内存）                   | 极低（零 RootFS，无 Guest OS）          |
| **内存安全性**   | 高（硬件级隔离）                             | 中等（逻辑隔离）                     | 高（类型安全、边界检查）                |
| **典型应用**     | 虚拟化                                       | 容器化                               | 沙盒化                                  |

#### 05.4.2 各范式内存管理模式映射

**各范式内存管理模式架构**：

```text
各范式内存管理模式架构对比:

虚拟化（独立物理内存）:
Host 物理内存 (HPA)
  ↓
EPT/NPT (硬件内存虚拟化)
  ↓
Guest 物理内存 (GPA)
  ↓
Guest OS 页表 (GVA → GPA)
  ↓
进程虚拟地址 (GVA)

容器化（共享内核内存）:
Host 物理内存 (HPA)
  ↓
Host OS 页表 (虚拟地址 → HPA)
  ↓
Host OS 虚拟地址空间
  ↓
Container 进程虚拟地址空间
  ↓
cgroup 内存限制

沙盒化（应用级内存）:
Host 物理内存 (HPA)
  ↓
Host OS 页表 (虚拟地址 → HPA)
  ↓
Runtime 进程虚拟地址空间
  ↓
Runtime 内存池
  ↓
Wasm 线性内存
  ↓
从 0 开始的线性地址
```

---

## 06 CPU 通道模型

### 06.1 物理 CPU 通道

#### 06.1.1 物理 CPU 通道定义

**物理 CPU 通道（Physical CPU Channel）定义**：

物理 CPU 通道是指 CPU 与系统其他组件（内存、I/O 设备）之间的物理连接和数据传输通
道。

**物理 CPU 通道类型**：

1. **CPU 总线（CPU Bus）**：

   - **结构**：CPU 与北桥/内存控制器之间的连接
   - **特征**：高带宽、低延迟、点对点连接
   - **应用**：CPU 与内存控制器通信

2. **QPI/UPI（Intel）**：

   - **QPI（QuickPath Interconnect）**：CPU 之间的互连
   - **UPI（Ultra Path Interconnect）**：QPI 的升级版
   - **特征**：高带宽、低延迟、NUMA 互连

3. **HyperTransport/Infinity Fabric（AMD）**：

   - **HyperTransport**：AMD CPU 之间的互连
   - **Infinity Fabric**：HyperTransport 的升级版
   - **特征**：高带宽、低延迟、NUMA 互连

#### 06.1.2 物理 CPU 通道在技术栈中的作用

**物理 CPU 通道映射**：

```text
物理 CPU 通道结构:

Intel 架构:
├── CPU Socket 0
│   ├── CPU Bus → 内存控制器
│   ├── QPI/UPI → CPU Socket 1
│   └── PCIe → I/O 设备
├── CPU Socket 1
│   ├── CPU Bus → 内存控制器
│   ├── QPI/UPI → CPU Socket 0
│   └── PCIe → I/O 设备
└── NUMA 互连
    └── QPI/UPI 提供 NUMA 互连

AMD 架构:
├── CPU Socket 0
│   ├── CPU Bus → 内存控制器
│   ├── Infinity Fabric → CPU Socket 1
│   └── PCIe → I/O 设备
├── CPU Socket 1
│   ├── CPU Bus → 内存控制器
│   ├── Infinity Fabric → CPU Socket 0
│   └── PCIe → I/O 设备
└── NUMA 互连
    └── Infinity Fabric 提供 NUMA 互连
```

### 06.2 逻辑 CPU 通道

#### 06.2.1 逻辑 CPU 通道定义

**逻辑 CPU 通道（Logical CPU Channel）定义**：

逻辑 CPU 通道是指操作系统或虚拟化层对 CPU 通信通道的逻辑抽象，包括调度队列、中断
处理、CPU 间通信等。

**逻辑 CPU 通道类型**：

1. **调度队列（Scheduling Queue）**：

   - **结构**：每个 CPU 核心有运行队列、等待队列
   - **特征**：进程/线程调度、负载均衡、NUMA 感知调度
   - **应用**：操作系统进程调度

2. **中断处理通道（Interrupt Channel）**：

   - **结构**：硬件中断 → CPU 核心 → 中断处理程序
   - **特征**：中断路由、中断亲和性、中断平衡
   - **应用**：I/O 中断处理、网络中断、存储中断

3. **CPU 间通信（Inter-CPU Communication）**：

   - **IPI（Inter-Processor Interrupt）**：CPU 间中断
   - **缓存一致性协议**：MESI、MOESI
   - **特征**：CPU 间同步、缓存同步

#### 06.2.2 逻辑 CPU 通道在技术栈中的作用

**逻辑 CPU 通道映射**：

```text
逻辑 CPU 通道结构:

操作系统逻辑通道:
├── 调度队列
│   ├── CPU 0 运行队列 (Run Queue)
│   ├── CPU 0 等待队列 (Wait Queue)
│   └── 负载均衡 (Load Balancing)
├── 中断处理通道
│   ├── 硬件中断 → CPU 0
│   ├── 中断路由 (IRQ Routing)
│   └── 中断亲和性 (IRQ Affinity)
└── CPU 间通信
    ├── IPI (Inter-Processor Interrupt)
    └── 缓存一致性协议 (MESI)

虚拟化逻辑通道:
├── vCPU 调度队列
│   ├── vCPU 0 → 物理 CPU 0-3 调度队列
│   └── NUMA 感知调度
├── 虚拟中断
│   ├── 虚拟中断注入 (Virtual Interrupt Injection)
│   └── 中断路由到 vCPU
└── vCPU 间通信
    └── 通过 Hypervisor 协调
```

### 06.3 CPU 通道映射

#### 06.3.1 物理 CPU 通道与逻辑 CPU 通道映射

**映射关系**：

```text
物理 CPU 通道 → 逻辑 CPU 通道映射:

物理层:
├── QPI/UPI 互连 (物理)
│   └── CPU Socket 0 ↔ CPU Socket 1
├── CPU Bus (物理)
│   └── CPU → 内存控制器
└── PCIe (物理)
    └── CPU → I/O 设备

逻辑层:
├── 调度队列 (逻辑)
│   └── 进程/线程调度通道
├── 中断处理通道 (逻辑)
│   └── 中断路由和处理
└── CPU 间通信 (逻辑)
    └── IPI、缓存一致性
```

#### 06.3.2 各范式 CPU 通道模型映射

**各范式 CPU 通道映射矩阵**：

| 维度              | 虚拟化                       | 容器化                     | 沙盒化                   |
| ----------------- | ---------------------------- | -------------------------- | ------------------------ |
| **物理 CPU 通道** | 直接访问（Type-1）或间接访问 | 直接访问                   | 直接访问                 |
| **逻辑 CPU 通道** | vCPU 调度队列、虚拟中断      | Host OS 调度队列、中断通道 | Runtime 线程池、事件循环 |
| **CPU 间通信**    | vCPU 间通过 Hypervisor 协调  | 直接 CPU 间通信（IPI）     | Runtime 内部协调         |
| **中断处理**      | 虚拟中断注入                 | 直接硬件中断处理           | Runtime 事件处理         |
| **调度通道**      | vCPU 调度队列                | 进程调度队列               | Runtime 任务队列         |
| **NUMA 感知**     | 支持（NUMA 感知调度）        | 支持（NUMA 感知调度）      | 有限（Runtime 抽象）     |

---

## 07 内存通道模型

### 07.1 物理内存通道

#### 07.1.1 物理内存通道定义

**物理内存通道（Physical Memory Channel）定义**：

物理内存通道是指 CPU 内存控制器与内存模块（DIMM）之间的物理连接和数据传输通道。

**物理内存通道类型**：

1. **内存通道（Memory Channel）**：

   - **结构**：内存控制器 → 内存通道 → DIMM 模块
   - **特征**：多通道并行、DDR 协议、高带宽
   - **应用**：DDR4/DDR5 内存访问

2. **内存总线（Memory Bus）**：

   - **结构**：内存控制器通过总线连接多个内存通道
   - **特征**：并行访问、带宽聚合、延迟优化
   - **应用**：多通道内存架构

3. **NUMA 互连**：

   - **结构**：NUMA 节点之间通过互连访问远程内存
   - **特征**：远程内存访问、带宽不对称、延迟更高
   - **应用**：多路服务器、NUMA 架构

#### 07.1.2 物理内存通道在技术栈中的作用

**物理内存通道映射**：

```text
物理内存通道结构:

双通道内存:
├── 内存控制器
│   ├── Channel 0 → DIMM 0, DIMM 1
│   └── Channel 1 → DIMM 2, DIMM 3
└── 并行访问
    ├── 带宽聚合
    └── 延迟优化

四通道内存:
├── 内存控制器
│   ├── Channel 0 → DIMM 0-3
│   ├── Channel 1 → DIMM 4-7
│   ├── Channel 2 → DIMM 8-11
│   └── Channel 3 → DIMM 12-15
└── 四通道并行访问
    ├── 带宽 = 4 × 单通道带宽
    └── 延迟优化

NUMA 内存通道:
├── NUMA Node 0
│   ├── 本地内存通道 (Local Memory Channel)
│   │   ├── 访问延迟: ~50ns
│   │   └── 带宽: ~50-100 GB/s
│   └── 远程内存通道 (Remote Memory Channel)
│       ├── 访问延迟: ~100-200ns
│       └── 带宽: ~20-50 GB/s
└── NUMA Node 1
    ├── 本地内存通道
    └── 远程内存通道
```

### 07.2 逻辑内存通道

#### 07.2.1 逻辑内存通道定义

**逻辑内存通道（Logical Memory Channel）定义**：

逻辑内存通道是指操作系统或虚拟化层对内存访问通道的逻辑抽象，包括页表、TLB、内存
分配器、NUMA 内存策略等。

**逻辑内存通道类型**：

1. **页表通道（Page Table Channel）**：

   - **结构**：虚拟地址 → 页表 → 物理地址
   - **特征**：多级页表、TLB 缓存、页表遍历
   - **应用**：虚拟内存管理

2. **内存分配通道（Memory Allocation Channel）**：

   - **伙伴系统（Buddy System）**：页级内存分配
   - **SLAB 分配器**：对象级内存分配
   - **特征**：按需分配、内存回收、内存碎片管理

3. **NUMA 内存策略通道**：

   - **本地内存优先（Local First）**：优先使用本地 NUMA 节点内存
   - **交错分配（Interleave）**：在多个 NUMA 节点间交错分配
   - **特征**：NUMA 感知、内存本地性优化

#### 07.2.2 逻辑内存通道在技术栈中的作用

**逻辑内存通道映射**：

```text
逻辑内存通道结构:

操作系统逻辑通道:
├── 页表通道
│   ├── 虚拟地址 → 页表 (Page Table)
│   ├── TLB (Translation Lookaside Buffer)
│   └── 页表遍历 (Page Table Walk)
├── 内存分配通道
│   ├── 伙伴系统 (Buddy System)
│   ├── SLAB 分配器
│   └── 内存回收 (Memory Reclaim)
└── NUMA 内存策略通道
    ├── 本地内存优先 (MPOL_LOCAL)
    ├── 偏好本地 (MPOL_PREFERRED)
    └── 交错分配 (MPOL_INTERLEAVE)

虚拟化逻辑通道:
├── Guest 页表通道
│   ├── GVA → GPA (Guest OS 页表)
│   └── GPA → HPA (EPT/NPT)
├── Guest 内存分配通道
│   └── Guest OS 内存分配器
└── NUMA 内存策略通道
    └── Guest OS NUMA 策略（如暴露 NUMA 拓扑）
```

### 07.3 内存通道映射

#### 07.3.1 物理内存通道与逻辑内存通道映射

**映射关系**：

```text
物理内存通道 → 逻辑内存通道映射:

物理层:
├── 内存通道 (物理)
│   ├── Channel 0: DIMM 0-3
│   ├── Channel 1: DIMM 4-7
│   └── Channel 2: DIMM 8-11
├── NUMA 互连 (物理)
│   └── NUMA Node 0 ↔ NUMA Node 1
└── 内存总线 (物理)
    └── 内存控制器 → 内存通道

逻辑层:
├── 页表通道 (逻辑)
│   └── 虚拟地址 → 物理地址
├── 内存分配通道 (逻辑)
│   └── 内存分配器
└── NUMA 内存策略通道 (逻辑)
    └── NUMA 感知内存分配
```

#### 07.3.2 各范式内存通道模型映射

**各范式内存通道映射矩阵**：

| 维度              | 虚拟化                           | 容器化                     | 沙盒化                   |
| ----------------- | -------------------------------- | -------------------------- | ------------------------ |
| **物理内存通道**  | 直接访问或间接访问               | 直接访问                   | 直接访问                 |
| **逻辑内存通道**  | Guest 页表通道 + EPT/NPT         | Host OS 页表通道           | Runtime 内存池通道       |
| **页表通道**      | GVA → GPA → HPA（三级转换）      | 虚拟地址 → HPA（二级转换） | Runtime 内部映射（简单） |
| **内存分配通道**  | Guest OS 内存分配器              | Host OS 内存分配器         | Runtime 内存分配器       |
| **NUMA 内存策略** | 支持（Guest OS NUMA 策略）       | 支持（Host OS NUMA 策略）  | 有限（Runtime 抽象）     |
| **TLB 管理**      | Guest TLB + Host TLB（两级 TLB） | Host TLB（单级 TLB）       | Runtime 内部缓存         |

---

## 08 CPU 设备模型

### 08.1 物理 CPU

#### 08.1.1 物理 CPU 定义

**物理 CPU（Physical CPU）定义**：

物理 CPU 是指硬件上的实际 CPU 核心，包括 CPU Socket、CPU Core、CPU Thread（超线
程）等物理资源。

**物理 CPU 层级结构**：

1. **CPU Socket（CPU 插槽）**：

   - **结构**：物理 CPU 芯片安装在主板的 CPU 插槽上
   - **特征**：物理独立芯片、独立缓存层次、NUMA 节点
   - **应用**：多路服务器、NUMA 架构

2. **CPU Core（CPU 核心）**：

   - **结构**：每个 CPU Socket 包含多个物理核心
   - **特征**：独立执行单元、独立 L1/L2 缓存、共享 L3 缓存
   - **应用**：多核处理器、并行计算

3. **CPU Thread（CPU 线程/超线程）**：

   - **结构**：每个 CPU Core 可以支持超线程（SMT/HT）
   - **特征**：逻辑线程、共享执行单元、独立寄存器
   - **应用**：提高 CPU 利用率、多线程应用

#### 08.1.2 物理 CPU 在技术栈中的作用

**物理 CPU 层级**：

```text
物理 CPU 层级结构:

CPU Socket 0 (物理)
├── CPU Core 0 (物理)
│   ├── CPU Thread 0 (物理) → 逻辑 CPU 0
│   └── CPU Thread 1 (物理) → 逻辑 CPU 1 (SMT/HT)
├── CPU Core 1 (物理)
│   ├── CPU Thread 0 (物理) → 逻辑 CPU 2
│   └── CPU Thread 1 (物理) → 逻辑 CPU 3 (SMT/HT)
└── L3 Cache (共享)

CPU Socket 1 (物理)
├── CPU Core 0 (物理)
│   ├── CPU Thread 0 (物理) → 逻辑 CPU 4
│   └── CPU Thread 1 (物理) → 逻辑 CPU 5 (SMT/HT)
├── CPU Core 1 (物理)
│   ├── CPU Thread 0 (物理) → 逻辑 CPU 6
│   └── CPU Thread 1 (物理) → 逻辑 CPU 7 (SMT/HT)
└── L3 Cache (共享)

NUMA 架构:
├── NUMA Node 0
│   └── CPU Socket 0 (本地内存)
├── NUMA Node 1
│   └── CPU Socket 1 (本地内存)
└── NUMA 互连
    └── QPI/UPI 或 Infinity Fabric
```

### 08.2 虚拟 CPU (vCPU)

#### 08.2.1 虚拟 CPU 定义

**虚拟 CPU（vCPU - Virtual CPU）定义**：

虚拟 CPU 是指 Hypervisor 为虚拟机创建的虚拟 CPU 抽象，Guest OS 将其视为物理
CPU。

**虚拟 CPU 特征**：

1. **vCPU 抽象**：

   - **结构**：Hypervisor 创建的虚拟 CPU 抽象
   - **特征**：Guest OS 视为物理 CPU、独立 CPU ID、独立调度实体
   - **应用**：虚拟机 CPU 资源配置

2. **vCPU 调度**：

   - **结构**：Hypervisor 将 vCPU 调度到物理 CPU
   - **特征**：动态调度、时间片分配、NUMA 感知调度
   - **应用**：多虚拟机 CPU 资源共享

3. **vCPU 拓扑暴露**：

   - **vCPU Socket 配置**：虚拟 Socket 数量
   - **vCPU Core 配置**：虚拟 Core 数量
   - **vCPU Thread 配置**：虚拟 Thread 数量（SMT/HT）
   - **特征**：Guest OS 看到的虚拟 CPU 拓扑

#### 08.2.2 虚拟 CPU 在技术栈中的作用

**虚拟 CPU 架构**：

```text
虚拟 CPU 架构:

Hypervisor 层:
├── vCPU 0 → 物理 CPU 0-3 (动态调度)
├── vCPU 1 → 物理 CPU 0-3 (动态调度)
├── vCPU 2 → 物理 CPU 4-7 (动态调度)
└── vCPU 3 → 物理 CPU 4-7 (动态调度)

Guest OS 层:
├── 识别虚拟 CPU 拓扑
│   ├── vCPU Socket 0 (虚拟)
│   │   ├── vCPU Core 0 (虚拟)
│   │   │   └── vCPU Thread 0 (虚拟) → vCPU 0
│   │   └── vCPU Core 1 (虚拟)
│   │       └── vCPU Thread 0 (虚拟) → vCPU 1
│   └── vCPU Socket 1 (虚拟)
│       ├── vCPU Core 0 (虚拟)
│       │   └── vCPU Thread 0 (虚拟) → vCPU 2
│       └── vCPU Core 1 (虚拟)
│           └── vCPU Thread 0 (虚拟) → vCPU 3
└── 在虚拟拓扑上运行调度器
```

### 08.3 逻辑 CPU

#### 08.3.1 逻辑 CPU 定义

**逻辑 CPU（Logical CPU）定义**：

逻辑 CPU 是指操作系统识别的 CPU 抽象，通常对应物理 CPU 的 Thread（包括超线程）。

**逻辑 CPU 特征**：

1. **操作系统视图**：

   - **结构**：操作系统识别的 CPU 抽象（如 `/proc/cpuinfo`）
   - **特征**：逻辑 CPU ID、调度队列、CPU 亲和性
   - **应用**：进程调度、CPU 绑定

2. **cgroup CPU 限制**：

   - **CPU 集合（cpuset）**：限制容器使用的逻辑 CPU
   - **CPU 份额（cpu.shares）**：CPU 时间份额分配
   - **CPU 配额（cpu.cfs_quota_us）**：CPU 时间配额限制
   - **特征**：资源限制、多租户隔离

3. **CPU 亲和性（CPU Affinity）**：

   - **结构**：将进程/线程绑定到特定逻辑 CPU
   - **特征**：避免上下文切换、提高缓存命中率、NUMA 本地性
   - **应用**：高性能应用、实时系统

#### 08.3.2 逻辑 CPU 在技术栈中的作用

**逻辑 CPU 架构**：

```text
逻辑 CPU 架构:

操作系统视图:
├── 逻辑 CPU 0-7 (对应物理 CPU Thread)
├── CPU 调度域
│   ├── NUMA 域
│   └── CPU Socket/Core/Thread 层级
└── 进程调度
    ├── CPU 0 运行队列
    ├── CPU 1 运行队列
    └── CPU 7 运行队列

容器化视图:
├── Container A
│   ├── cpuset: CPU 0-3
│   └── cpu.shares: 512
├── Container B
│   ├── cpuset: CPU 4-7
│   └── cpu.shares: 512
└── Container C
    ├── cpuset: CPU 0-7
    └── cpu.shares: 1024

沙盒化视图:
├── Runtime Worker Thread 0 → 逻辑 CPU 0-7 (Host OS 调度)
├── Runtime Worker Thread 1 → 逻辑 CPU 0-7 (Host OS 调度)
└── Runtime 内部任务调度
    └── Wasm 函数/模块执行
```

### 08.4 CPU 设备模型映射

#### 08.4.1 CPU 设备模型对比矩阵

**CPU 设备模型对比矩阵**：

| 维度             | 物理 CPU       | 虚拟 CPU (vCPU)       | 逻辑 CPU                         |
| ---------------- | -------------- | --------------------- | -------------------------------- |
| **抽象层级**     | 硬件物理资源   | Hypervisor 虚拟抽象   | 操作系统逻辑抽象                 |
| **资源隔离**     | 物理隔离       | 硬件级隔离（EPT/NPT） | 逻辑隔离（cgroup）               |
| **调度方式**     | 直接执行       | Hypervisor 两级调度   | Host OS 单级调度                 |
| **CPU 拓扑暴露** | 完整物理拓扑   | 虚拟拓扑（可配置）    | 物理拓扑（容器化）或抽象（沙盒） |
| **NUMA 感知**    | 完整 NUMA 拓扑 | 支持（NUMA 拓扑暴露） | 支持（NUMA 感知调度）            |
| **CPU 绑定**     | N/A            | vCPU Pinning          | CPU 亲和性（cpuset）             |
| **资源限制**     | N/A            | vCPU 数量限制         | cgroup CPU 限制                  |
| **典型应用**     | 物理服务器     | 虚拟化                | 容器化、沙盒化                   |

#### 08.4.2 各范式 CPU 设备模型映射

**各范式 CPU 设备模型架构**：

```text
各范式 CPU 设备模型架构对比:

虚拟化（vCPU）:
物理 CPU
  ↓
Hypervisor
  ↓
vCPU (虚拟 CPU)
  ↓
Guest OS
  ↓
进程/线程

容器化（逻辑 CPU）:
物理 CPU
  ↓
Host OS
  ↓
逻辑 CPU (cgroup CPU 限制)
  ↓
Container 进程

沙盒化（Runtime 线程）:
物理 CPU
  ↓
Host OS
  ↓
逻辑 CPU (Host OS 调度)
  ↓
Runtime Worker Thread
  ↓
Runtime 任务调度
  ↓
Wasm 函数/模块
```

---

## 09 内存设备模型

### 09.1 物理内存

#### 09.1.1 物理内存定义

**物理内存（Physical Memory）定义**：

物理内存是指硬件上的实际内存模块（DIMM），包括 DDR4/DDR5 内存条、内存容量、内存
频率等物理特性。

**物理内存类型**：

1. **DDR4 内存**：

   - **结构**：DDR4 DIMM 模块
   - **特征**：频率 2133-3200 MHz、容量 4-64 GB/条、电压 1.2V
   - **应用**：服务器、工作站

2. **DDR5 内存**：

   - **结构**：DDR5 DIMM 模块
   - **特征**：频率 4800-6400 MHz、容量 8-128 GB/条、电压 1.1V
   - **应用**：新一代服务器、高性能计算

3. **持久内存（PMEM）**：

   - **结构**：Intel Optane DC Persistent Memory
   - **特征**：非易失性、大容量、延迟高于 DRAM
   - **应用**：内存数据库、大数据分析

#### 09.1.2 物理内存在技术栈中的作用

**物理内存层级**：

```text
物理内存层级结构:

物理内存模块 (DIMM):
├── DIMM 0 (DDR4/DDR5, 32GB)
├── DIMM 1 (DDR4/DDR5, 32GB)
├── DIMM 2 (DDR4/DDR5, 32GB)
└── DIMM 3 (DDR4/DDR5, 32GB)

内存通道:
├── Channel 0: DIMM 0, DIMM 1
├── Channel 1: DIMM 2, DIMM 3
└── 并行访问，带宽聚合

NUMA 内存:
├── NUMA Node 0
│   └── 本地内存: 128GB (DIMM 0-3)
├── NUMA Node 1
│   └── 本地内存: 128GB (DIMM 4-7)
└── NUMA 互连
    └── 远程内存访问
```

### 09.2 虚拟内存

#### 09.2.1 虚拟内存定义

**虚拟内存（Virtual Memory）定义**：

虚拟内存是指操作系统管理的虚拟地址空间，通过页表映射到物理内存。

**虚拟内存特征**：

1. **虚拟地址空间**：

   - **结构**：每个进程有独立的虚拟地址空间（32 位：4GB，64 位：128TB+）
   - **特征**：地址空间隔离、按需分配、页式管理
   - **应用**：进程隔离、内存保护

2. **页表映射**：

   - **结构**：虚拟地址 → 页表 → 物理地址
   - **特征**：多级页表、TLB 缓存、页表遍历
   - **应用**：虚拟内存管理

3. **Guest 物理内存（GPA）**：

   - **结构**：Guest OS 看到的内存地址空间
   - **特征**：独立地址空间、硬件级隔离、EPT/NPT 映射
   - **应用**：虚拟机内存隔离

#### 09.2.2 虚拟内存在技术栈中的作用

**虚拟内存架构**：

```text
虚拟内存架构:

操作系统虚拟内存:
├── 进程虚拟地址空间
│   ├── 用户空间 (User Space)
│   │   ├── 代码段
│   │   ├── 数据段
│   │   ├── 堆 (Heap)
│   │   └── 栈 (Stack)
│   └── 内核空间 (Kernel Space)
├── 页表 (Page Table)
│   └── 虚拟地址 → 物理地址映射
└── TLB (Translation Lookaside Buffer)
    └── 页表缓存

虚拟化虚拟内存:
├── Guest 虚拟地址 (GVA)
│   └── Guest OS 管理的虚拟地址空间
├── Guest 物理地址 (GPA)
│   └── Guest OS 看到的内存地址空间
└── Host 物理地址 (HPA)
    └── 实际物理内存地址
    └── 通过 EPT/NPT 映射
```

### 09.3 逻辑内存

#### 09.3.1 逻辑内存定义

**逻辑内存（Logical Memory）定义**：

逻辑内存是指应用程序或运行时看到的内存抽象，包括线性内存（Wasm）、堆内存、栈内存
等。

**逻辑内存类型**：

1. **线性内存（Linear Memory）**：

   - **结构**：Wasm 模块的单一连续地址空间
   - **特征**：从 0 开始的线性地址、大小可动态增长（最大 4GB）、单一片连续内存
   - **应用**：Wasm 模块内存管理

2. **堆内存（Heap Memory）**：

   - **结构**：应用程序动态分配的内存区域
   - **特征**：动态分配、手动释放（C/C++）或自动回收（GC）
   - **应用**：应用程序数据存储

3. **栈内存（Stack Memory）**：

   - **结构**：函数调用栈、局部变量
   - **特征**：LIFO、自动管理、快速分配
   - **应用**：函数调用、局部变量

#### 09.3.2 逻辑内存在技术栈中的作用

**逻辑内存架构**：

```text
逻辑内存架构:

Wasm 线性内存:
├── Wasm Module A
│   └── 线性内存 (Linear Memory)
│       ├── 从 0 开始的线性地址
│       ├── 单一片连续内存
│       └── 大小可动态增长（最大 4GB）
├── Wasm Module B
│   └── 独立线性内存
└── Wasm Module C
    └── 独立线性内存

Runtime 内存池:
├── Runtime 分配物理内存
│   └── Host OS 虚拟地址空间
├── Runtime 管理 Wasm 线性内存
│   └── 线性内存 → Host OS 虚拟地址映射
└── Runtime 内存限制
    └── 可选的内存限制

应用堆内存:
├── 应用程序堆
│   ├── malloc/free (C/C++)
│   └── 垃圾回收 (GC, 如 Java/Go)
└── Host OS 虚拟地址空间
    └── 进程堆内存区域
```

### 09.4 内存设备模型映射

#### 09.4.1 内存设备模型对比矩阵

**内存设备模型对比矩阵**：

| 维度          | 物理内存        | 虚拟内存（Guest 物理内存）   | 逻辑内存（线性内存）                 |
| ------------- | --------------- | ---------------------------- | ------------------------------------ |
| **抽象层级**  | 硬件物理资源    | Hypervisor/Guest OS 虚拟抽象 | Runtime 应用级抽象                   |
| **资源隔离**  | 物理隔离        | 硬件级隔离（EPT/NPT）        | 应用级隔离（线性内存隔离）           |
| **地址空间**  | 物理地址（HPA） | Guest 物理地址（GPA）        | 线性地址（从 0 开始）                |
| **地址转换**  | N/A             | GVA → GPA → HPA（三级转换）  | 线性地址 → Runtime 内存池            |
| **内存管理**  | 硬件内存控制器  | Hypervisor + Guest OS 两级   | Runtime 应用级管理                   |
| **内存共享**  | 不支持          | 不支持（独立物理内存）       | 支持（Runtime 内存池，但模块间隔离） |
| **NUMA 感知** | 完整 NUMA 拓扑  | 支持（NUMA 拓扑暴露）        | 有限（Runtime 抽象）                 |
| **内存开销**  | N/A             | 高（Guest OS 内存开销）      | 极低（零 RootFS）                    |
| **典型应用**  | 物理服务器      | 虚拟化                       | 沙盒化（Wasm）                       |

#### 09.4.2 各范式内存设备模型映射

**各范式内存设备模型架构**：

```text
各范式内存设备模型架构对比:

虚拟化（Guest 物理内存）:
Host 物理内存 (HPA)
  ↓
EPT/NPT (硬件内存虚拟化)
  ↓
Guest 物理内存 (GPA)
  ↓
Guest OS 页表 (GVA → GPA)
  ↓
Guest 虚拟地址 (GVA)

容器化（Host OS 虚拟内存）:
Host 物理内存 (HPA)
  ↓
Host OS 页表 (虚拟地址 → HPA)
  ↓
Host OS 虚拟地址空间
  ↓
Container 进程虚拟地址空间

沙盒化（Wasm 线性内存）:
Host 物理内存 (HPA)
  ↓
Host OS 页表 (虚拟地址 → HPA)
  ↓
Runtime 进程虚拟地址空间
  ↓
Runtime 内存池
  ↓
Wasm 线性内存
  ↓
从 0 开始的线性地址
```

---

## 10 CPU/内存 协议栈模型

### 10.1 CPU 调度协议栈

#### 10.1.1 物理 CPU 调度协议栈

**物理 CPU 调度协议栈**：

```text
物理 CPU 调度协议栈:

硬件层:
├── 物理 CPU 核心
├── 硬件中断控制器 (APIC)
└── CPU 间互连 (QPI/UPI/Infinity Fabric)

操作系统层:
├── CPU 调度器 (CFS/RT/Deadline)
├── 中断处理程序 (IRQ Handler)
├── CPU 调度域 (Scheduling Domain)
└── CPU 亲和性 (CPU Affinity)

应用层:
├── 进程/线程
├── CPU 绑定 (CPU Binding)
└── 负载均衡 (Load Balancing)
```

#### 10.1.2 虚拟化 CPU 调度协议栈

**虚拟化 CPU 调度协议栈**：

```text
虚拟化 CPU 调度协议栈:

硬件层:
├── 物理 CPU 核心
└── 硬件中断控制器

Hypervisor 层:
├── vCPU 调度器 (Hypervisor Scheduler)
├── 虚拟中断注入 (Virtual Interrupt Injection)
├── vCPU 调度域
└── vCPU Pinning (可选)

Guest OS 层:
├── Guest OS 调度器 (CFS/RT)
├── Guest OS 中断处理
└── Guest OS CPU 亲和性

Guest 应用层:
├── Guest 进程/线程
└── Guest 应用 CPU 绑定
```

#### 10.1.3 容器化 CPU 调度协议栈

**容器化 CPU 调度协议栈**：

```text
容器化 CPU 调度协议栈:

硬件层:
├── 物理 CPU 核心
└── 硬件中断控制器

Host OS 层:
├── Host OS 调度器 (CFS/RT/Deadline)
├── 中断处理程序
├── CPU 调度域
└── cgroup CPU 控制器
    ├── cpu.shares (CPU 份额)
    ├── cpu.cfs_quota_us (CPU 配额)
    └── cpuset (CPU 集合)

Container 层:
├── Container 进程
├── cgroup CPU 限制
└── Container 应用 CPU 绑定
```

#### 10.1.4 沙盒化 CPU 调度协议栈

**沙盒化 CPU 调度协议栈**：

```text
沙盒化 CPU 调度协议栈:

硬件层:
├── 物理 CPU 核心
└── 硬件中断控制器

Host OS 层:
├── Host OS 调度器 (CFS)
├── 中断处理程序
└── CPU 调度域

Runtime 层:
├── Runtime 线程池 (Worker Thread Pool)
├── Runtime 任务调度 (Task Scheduling)
├── Runtime 事件循环 (Event Loop)
└── Runtime CPU 限制 (可选)

Wasm 应用层:
├── Wasm 模块
├── Wasm 函数执行
└── 不感知 CPU 拓扑（完全抽象）
```

### 10.2 内存管理协议栈

#### 10.2.1 物理内存管理协议栈

**物理内存管理协议栈**：

```text
物理内存管理协议栈:

硬件层:
├── 物理内存模块 (DIMM)
├── 内存控制器 (Memory Controller)
├── 内存通道 (Memory Channel)
└── NUMA 互连

操作系统层:
├── 页表 (Page Table)
├── TLB (Translation Lookaside Buffer)
├── 内存分配器 (Buddy System/SLAB)
├── NUMA 内存策略
└── 内存回收 (Memory Reclaim)

应用层:
├── 进程虚拟地址空间
├── 内存分配 (malloc/new)
└── 内存释放 (free/delete)
```

#### 10.2.2 虚拟化内存管理协议栈

**虚拟化内存管理协议栈**：

```text
虚拟化内存管理协议栈:

硬件层:
├── 物理内存模块
├── 内存控制器
└── NUMA 互连

Hypervisor 层:
├── EPT/NPT (硬件内存虚拟化)
├── Guest 物理内存 (GPA) 分配
├── 内存气球驱动 (Memory Balloon)
├── 内存交换/压缩
└── NUMA 拓扑暴露（可选）

Guest OS 层:
├── Guest OS 页表 (GVA → GPA)
├── Guest OS TLB
├── Guest OS 内存分配器
└── Guest OS NUMA 策略（如暴露）

Guest 应用层:
├── Guest 进程虚拟地址空间
└── Guest 应用内存分配
```

#### 10.2.3 容器化内存管理协议栈

**容器化内存管理协议栈**：

```text
容器化内存管理协议栈:

硬件层:
├── 物理内存模块
├── 内存控制器
└── NUMA 互连

Host OS 层:
├── Host OS 页表 (虚拟地址 → HPA)
├── Host OS TLB
├── Host OS 内存分配器
├── NUMA 内存策略
└── cgroup 内存控制器
    ├── memory.limit_in_bytes (内存限制)
    ├── memory.oom_control (OOM 控制)
    └── memory.stat (内存统计)

Container 层:
├── Container 进程虚拟地址空间
├── cgroup 内存限制
└── Container 应用内存分配
```

#### 10.2.4 沙盒化内存管理协议栈

**沙盒化内存管理协议栈**：

```text
沙盒化内存管理协议栈:

硬件层:
├── 物理内存模块
├── 内存控制器
└── NUMA 互连

Host OS 层:
├── Host OS 页表
├── Host OS TLB
├── Host OS 内存分配器
└── NUMA 内存策略

Runtime 层:
├── Runtime 内存池 (Memory Pool)
├── Wasm 线性内存管理
├── Runtime 内存分配器
└── Runtime 内存限制（可选）

Wasm 应用层:
├── Wasm 线性内存 (Linear Memory)
├── Wasm 内存操作 (load/store/memory.grow)
└── 不感知物理内存拓扑（完全抽象）
```

### 10.3 CPU/内存协议栈映射

#### 10.3.1 CPU/内存协议栈对比矩阵

**CPU/内存协议栈对比矩阵**：

| 维度             | 虚拟化                               | 容器化                        | 沙盒化                           |
| ---------------- | ------------------------------------ | ----------------------------- | -------------------------------- |
| **CPU 调度层级** | Hypervisor + Guest OS（两级）        | Host OS（单级）               | Runtime + Host OS（应用级+单级） |
| **内存管理层级** | Hypervisor + Guest OS（两级）        | Host OS（单级）               | Runtime + Host OS（应用级+单级） |
| **地址转换层级** | GVA → GPA → HPA（三级转换，EPT/NPT） | 虚拟地址 → HPA（二级转换）    | Runtime 内部映射（简单）         |
| **TLB 层级**     | Guest TLB + Host TLB（两级 TLB）     | Host TLB（单级 TLB）          | Runtime 内部缓存                 |
| **调度开销**     | 高（两级调度延迟叠加）               | 低（单级调度延迟）            | 中等（Runtime + Host OS）        |
| **内存开销**     | 高（Guest OS 内存开销）              | 低（共享内核内存）            | 极低（零 RootFS）                |
| **NUMA 感知**    | 支持（NUMA 拓扑暴露给 Guest OS）     | 支持（Host OS NUMA 感知）     | 有限（Runtime 抽象）             |
| **资源隔离**     | 硬件级隔离（EPT/NPT）                | 逻辑隔离（命名空间 + cgroup） | 应用级隔离（线性内存隔离）       |

#### 10.3.2 各范式 CPU/内存协议栈映射

**各范式 CPU/内存协议栈架构对比**：

```text
各范式 CPU/内存协议栈架构对比:

虚拟化:
├── CPU 调度协议栈
│   ├── Hypervisor 层: vCPU 调度
│   └── Guest OS 层: 进程调度
└── 内存管理协议栈
    ├── Hypervisor 层: EPT/NPT、GPA 分配
    └── Guest OS 层: GVA → GPA、内存分配

容器化:
├── CPU 调度协议栈
│   └── Host OS 层: 进程调度 + cgroup
└── 内存管理协议栈
    └── Host OS 层: 虚拟地址 → HPA、内存分配 + cgroup

沙盒化:
├── CPU 调度协议栈
│   ├── Host OS 层: 线程调度
│   └── Runtime 层: 任务调度
└── 内存管理协议栈
    ├── Host OS 层: 虚拟地址 → HPA、内存分配
    └── Runtime 层: 线性内存管理
```

---

## 11 架构对比分析

### 11.1 CPU/内存架构同构性分析

**CPU/内存架构同构性**：

| 维度         | 虚拟化               | 容器化               | 沙盒化                 |
| ------------ | -------------------- | -------------------- | ---------------------- |
| **抽象层级** | 硬件级抽象（vCPU）   | 操作系统级抽象       | 应用级抽象（Runtime）  |
| **资源抽象** | vCPU、Guest 物理内存 | cgroup、虚拟地址空间 | Runtime 线程、线性内存 |
| **管理层级** | 两级管理             | 单级管理             | 应用级+单级管理        |
| **隔离机制** | 硬件级隔离           | 逻辑隔离             | 应用级隔离             |
| **拓扑暴露** | 虚拟拓扑（可配置）   | 物理拓扑（共享）     | 抽象拓扑（隐藏）       |

**同构性总结**：

- **虚拟化**：硬件级抽象、两级管理、硬件级隔离 → **完整硬件抽象**
- **容器化**：操作系统级抽象、单级管理、逻辑隔离 → **操作系统抽象**
- **沙盒化**：应用级抽象、应用级+单级管理、应用级隔离 → **应用抽象**

### 11.2 CPU/内存架构等价性分析

**CPU/内存架构等价性**：

| 功能维度      | 虚拟化                | 容器化            | 沙盒化              |
| ------------- | --------------------- | ----------------- | ------------------- |
| **CPU 调度**  | Hypervisor + Guest OS | Host OS           | Runtime + Host OS   |
| **内存管理**  | Hypervisor + Guest OS | Host OS           | Runtime + Host OS   |
| **资源隔离**  | 硬件级隔离            | 逻辑隔离          | 应用级隔离          |
| **资源限制**  | vCPU/内存配置         | cgroup 限制       | Runtime 限制        |
| **NUMA 感知** | 支持（拓扑暴露）      | 支持（NUMA 感知） | 有限（抽象）        |
| **性能开销**  | 高（两级管理）        | 低（单级管理）    | 中等（应用级+单级） |

**等价性总结**：

- **功能等价性**：三种范式都提供 CPU/内存资源管理和隔离，但抽象层级不同
- **性能等价性**：容器化 > 沙盒化 > 虚拟化（性能开销从低到高）
- **隔离等价性**：虚拟化 > 沙盒化 > 容器化（隔离强度从强到弱）

### 11.3 CPU/内存架构性能对比

**CPU/内存架构性能对比矩阵**：

| 性能维度           | 虚拟化                      | 容器化             | 沙盒化                    |
| ------------------ | --------------------------- | ------------------ | ------------------------- |
| **CPU 调度延迟**   | 高（两级调度）              | 低（单级调度）     | 中等（应用级+单级）       |
| **上下文切换开销** | 高（Guest OS + Hypervisor） | 低（只有 Host OS） | 中等（Runtime + Host OS） |
| **内存访问延迟**   | 中等（三级地址转换）        | 低（二级地址转换） | 低（Runtime 内部映射）    |
| **TLB 命中率**     | 中等（两级 TLB）            | 高（单级 TLB）     | 高（Runtime 缓存）        |
| **内存开销**       | 高（Guest OS 开销）         | 低（共享内核）     | 极低（零 RootFS）         |
| **启动时间**       | 慢（Guest OS 启动）         | 快（进程启动）     | 极快（模块加载）          |
| **CPU 利用率**     | 低（两级调度开销）          | 高（单级调度）     | 中等（Runtime 开销）      |

**性能总结**：

- **容器化**：最佳性能（低延迟、低开销、高利用率）
- **沙盒化**：良好性能（中等延迟、极低开销、快速启动）
- **虚拟化**：较低性能（高延迟、高开销、较低利用率）

### 11.4 CPU/内存架构安全性对比

**CPU/内存架构安全性对比矩阵**：

| 安全维度         | 虚拟化                 | 容器化         | 沙盒化                   |
| ---------------- | ---------------------- | -------------- | ------------------------ |
| **隔离强度**     | 高（硬件级隔离）       | 中（逻辑隔离） | 高（应用级隔离）         |
| **攻击面**       | 小（Guest OS 隔离）    | 大（共享内核） | 小（Runtime 隔离）       |
| **内存安全**     | 高（EPT/NPT 硬件隔离） | 中（进程隔离） | 高（类型安全、边界检查） |
| **CPU 安全**     | 高（vCPU 隔离）        | 中（进程隔离） | 中（Runtime 线程隔离）   |
| **内核攻击风险** | 低（独立 Guest OS）    | 高（共享内核） | 低（无内核依赖）         |
| **侧信道攻击**   | 中（NUMA 等）          | 高（共享硬件） | 低（Runtime 抽象）       |

**安全性总结**：

- **虚拟化**：高安全性（硬件级隔离、独立 Guest OS）
- **沙盒化**：高安全性（应用级隔离、类型安全、无内核依赖）
- **容器化**：中等安全性（逻辑隔离、共享内核）

---

## 12 总结与展望

### 12.1 总结

本文档系统地解释和论证了虚拟化、容器化、沙盒化三种范式中的 **CPU 与内存**相关的
技术术语、概念、功能、关系和应用场景。

**核心内容总结**：

1. **CPU 拓扑结构**：

   - **物理 CPU 拓扑**：SMP/NUMA 架构、缓存层次结构
   - **逻辑 CPU 拓扑**：CPU 亲和性、CPU 集、CPU 调度域
   - **各范式映射**：虚拟化（vCPU）、容器化（cgroup）、沙盒化（Runtime 线程）

2. **内存拓扑结构**：

   - **物理内存拓扑**：UMA/NUMA 架构、内存层次结构
   - **逻辑内存拓扑**：虚拟内存空间、内存节点、内存区域
   - **各范式映射**：虚拟化（Guest 物理内存）、容器化（Host OS 虚拟地址）、沙盒
     化（线性内存）

3. **CPU 执行模式**：

   - **两级调度**：虚拟化（Hypervisor + Guest OS）
   - **单级调度**：容器化（Host OS）
   - **应用级调度**：沙盒化（Runtime + Host OS）

4. **内存管理模式**：

   - **独立物理内存**：虚拟化（Guest 物理内存、EPT/NPT）
   - **共享内核内存**：容器化（Host OS 虚拟地址空间）
   - **应用级内存**：沙盒化（Wasm 线性内存）

5. **通道模型**：

   - **CPU 通道**：物理 CPU 通道（QPI/UPI/Infinity Fabric）、逻辑 CPU 通道（调度
     队列、中断处理）
   - **内存通道**：物理内存通道（内存通道、NUMA 互连）、逻辑内存通道（页表、内存
     分配）

6. **设备模型**：

   - **CPU 设备**：物理 CPU、虚拟 CPU（vCPU）、逻辑 CPU
   - **内存设备**：物理内存、虚拟内存（Guest 物理内存）、逻辑内存（线性内存）

7. **协议栈模型**：

   - **CPU 调度协议栈**：硬件层、操作系统层、应用层
   - **内存管理协议栈**：硬件层、操作系统层、应用层

8. **架构对比**：
   - **同构性**：抽象层级、管理层级、隔离机制的异同
   - **等价性**：功能等价性、性能等价性、隔离等价性
   - **性能对比**：调度延迟、内存访问延迟、开销对比
   - **安全性对比**：隔离强度、攻击面、内存安全

### 12.2 技术趋势与展望

**技术发展趋势**：

1. **虚拟化趋势**：

   - 硬件虚拟化技术持续优化（EPT/NPT 性能提升）
   - 轻量级虚拟化（Firecracker、gVisor）
   - 硬件加速（SR-IOV、DPU）

2. **容器化趋势**：

   - 容器运行时优化（containerd、CRI-O）
   - 安全容器（Kata Containers、gVisor）
   - 资源隔离增强（cgroup v2）

3. **沙盒化趋势**：
   - WebAssembly 生态发展（WASI、WASM Edge）
   - Runtime 性能优化（WasmEdge、Wasmer）
   - 多语言支持（Rust、Go、Python 等）

**未来展望**：

1. **混合架构**：虚拟化、容器化、沙盒化的混合使用
2. **性能优化**：降低各范式的性能开销
3. **安全性增强**：提高各范式的隔离强度
4. **标准化**：统一的资源管理和接口标准

---

**文档版本**：v1.0 **最后更新**：2025-11-03 **维护者**：文档维护团队

---

_本文档为 CPU/内存概念与技术名词论证的核心文档，持续更新和完善中。_
